name: 'Deploy Terraform Infrastructure'

on:
  push:
    branches: [ "main" ]
    paths:
      - 'infrastructure/terraform/**'
      - '.github/workflows/deploy_terraform.yml'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  terraform:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
        working-directory: infrastructure/terraform
    env:
      TF_IN_AUTOMATION: "true"
      TF_VAR_frontend_waf_name: ${{ vars.FRONTEND_WAF_NAME }}
      # Set to "false" unless you actually have a CloudFront-scoped WAF created.
      TF_VAR_attach_frontend_waf: "false"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-central-1

      #---------- Network preflight + Terraform CLI mirror to avoid registry.terraform.io ----------
      - name: Preflight connectivity to Terraform endpoints
        shell: bash
        run: |
          set -euo pipefail
          echo "Checking connectivity to registry.terraform.io and releases.hashicorp.com ..."
          for host in "https://registry.terraform.io/.well-known/terraform.json" "https://releases.hashicorp.com"; do
            if curl -fsSL --max-time 10 "$host" >/dev/null; then
              echo "OK: $host"
            else
              echo "WARN: Cannot reach $host (continuing with mirror config if possible)"
            fi
          done

      - name: Configure Terraform CLI to use HashiCorp releases mirror
        shell: bash
        run: |
          set -euo pipefail
          cat > "${HOME}/.terraformrc" <<'RC'
          provider_installation {
            network_mirror {
              url = "https://releases.hashicorp.com"
              include = ["hashicorp/*"]
            }
            direct {
              exclude = ["hashicorp/*"]
            }
          }
          RC
          echo "Wrote ${HOME}/.terraformrc:"
          sed -n '1,200p' "${HOME}/.terraformrc"

      - name: Prepare Terraform plugin cache dir
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${HOME}/.terraform.d/plugin-cache"
          echo "TF_PLUGIN_CACHE_DIR=${HOME}/.terraform.d/plugin-cache" >> "$GITHUB_ENV"

      - name: Cache Terraform plugin cache
        uses: actions/cache@v4
        with:
          path: ~/.terraform.d/plugin-cache
          key: tf-plugin-cache-${{ runner.os }}-${{ hashFiles('infrastructure/terraform/**/*.tf','infrastructure/terraform/.terraform.lock.hcl') }}
          restore-keys: |
            tf-plugin-cache-${{ runner.os }}-

      #---------- Backend bootstrap ----------
      - name: Bootstrap remote state (S3+DDB)
        env:
          AWS_REGION: eu-central-1
        run: |
          set -euo pipefail
          BUCKET="navot-terraform-state-1"
          REGION="${AWS_REGION}"
          DDB_TABLE="terraform-lock-table"

          # --- S3 backend bucket (idempotent) ---
          if ! aws s3api head-bucket --bucket "$BUCKET" >/dev/null 2>&1; then
            aws s3api create-bucket \
              --bucket "$BUCKET" \
              --region "$REGION" \
              --create-bucket-configuration LocationConstraint="$REGION"
            aws s3api put-bucket-versioning --bucket "$BUCKET" --versioning-configuration Status=Enabled
            aws s3api put-bucket-encryption --bucket "$BUCKET" --server-side-encryption-configuration '{"Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]}'
            aws s3api put-public-access-block --bucket "$BUCKET" --public-access-block-configuration '{
              "BlockPublicAcls": true,
              "IgnorePublicAcls": true,
              "BlockPublicPolicy": true,
              "RestrictPublicBuckets": true
            }'
          else
            echo "S3 state bucket exists; continuing."
          fi

          # --- DynamoDB lock table (idempotent & race-safe) ---
          if ! aws dynamodb describe-table --table-name "$DDB_TABLE" >/dev/null 2>&1; then
            if ! aws dynamodb create-table \
              --table-name "$DDB_TABLE" \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST >/dev/null 2>&1; then
              if aws dynamodb describe-table --table-name "$DDB_TABLE" >/dev/null 2>&1; then
                echo "DynamoDB lock table already exists; continuing."
              else
                echo "Failed to create or verify DynamoDB lock table '$DDB_TABLE'." >&2
                exit 1
              fi
            fi
            aws dynamodb wait table-exists --table-name "$DDB_TABLE"
          else
            echo "DynamoDB lock table exists; continuing."
          fi

      #---------- Terraform operations with retries ----------
      - name: Terraform Init (with retries)
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          set -euo pipefail
          n=0
          until [ $n -ge 5 ]; do
            terraform init -reconfigure && break
            n=$((n+1))
            echo "terraform init failed (attempt $n). Retrying in $((n*10))s ..."
            sleep $((n*10))
          done

      - name: Import deploy artifacts bucket (if exists)
        id: import_artifacts_bucket
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          set -euo pipefail
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ARTIFACT_BUCKET="nat20scheduling-com-deploy-artifacts-${ACCOUNT_ID}"

          if aws s3api head-bucket --bucket "$ARTIFACT_BUCKET" 2>/dev/null; then
            if ! terraform state show aws_s3_bucket.deploy_artifacts >/dev/null 2>&1; then
              echo "Importing existing bucket $ARTIFACT_BUCKET into Terraform state..."
              terraform import aws_s3_bucket.deploy_artifacts "$ARTIFACT_BUCKET"
            else
              echo "Bucket already managed by Terraform state."
            fi
          else
            echo "No existing deploy artifacts bucket found; Terraform will create it."
          fi

      - name: Terraform Validate
        env:
          TF_IN_AUTOMATION: "true"
        run: terraform validate

      - name: Terraform Plan
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          terraform plan -input=false \
            -var "frontend_waf_name=${{ vars.FRONTEND_WAF_NAME }}" \
            -var "attach_frontend_waf=${{ env.TF_VAR_attach_frontend_waf }}"

      - name: Terraform Apply
        if: github.ref == 'refs/heads/main'
        env:
          TF_IN_AUTOMATION: "true"
        run: |
          terraform apply -auto-approve -input=false \
            -var "frontend_waf_name=${{ vars.FRONTEND_WAF_NAME }}" \
            -var "attach_frontend_waf=${{ env.TF_VAR_attach_frontend_waf }}"
