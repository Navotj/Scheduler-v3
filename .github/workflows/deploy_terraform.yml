name: Terraform Apply (EKS bootstrap-safe)

on:
  workflow_dispatch: {}
  push:
    paths:
      - ".github/workflows/deploy_terraform.yml"

jobs:
  tf-apply:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: eu-central-1
      TF_PLUGIN_CACHE_DIR: ${{ github.workspace }}/.tf-plugin-cache
      TF_VAR_admin_principal_arn: ${{ secrets.EKS_ADMIN_PRINCIPAL_ARN }}
      CLUSTER_NAME: nat20-eks

    defaults:
      run:
        shell: bash
        working-directory: infrastructure/terraform

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: gh-terraform-apply

      - name: Who am I?
        run: aws sts get-caller-identity

      - name: Prepare Terraform plugin cache
        run: |
          set -euo pipefail
          mkdir -p "$TF_PLUGIN_CACHE_DIR"
          printf 'plugin_cache_dir = "%s"\n' "$TF_PLUGIN_CACHE_DIR" > ~/.terraformrc
          ls -la "$TF_PLUGIN_CACHE_DIR"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.5

      - name: Terraform Init
        run: terraform init -input=false

      - name: Probe EKS cluster existence
        id: probe
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail
          if aws eks describe-cluster --region "${AWS_REGION}" --name "${CLUSTER_NAME}" >/dev/null 2>&1; then
            echo "exists=true" >> "$GITHUB_OUTPUT"
            echo "Cluster exists."
          else
            echo "exists=false" >> "$GITHUB_OUTPUT"
            echo "Cluster missing."
          fi

      - name: Prune state if cluster is missing (remove EKS/Helm/K8s/IRSA-bound)
        if: steps.probe.outputs.exists == 'false'
        run: |
          set -euo pipefail
          terraform state list || true
          PATTERN='^(helm_release\.|kubernetes_|aws_eks_|aws_iam_openid_connect_provider\.eks$)'
          MATCHES="$(terraform state list | grep -E "$PATTERN" || true)"
          if [ -n "$MATCHES" ]; then
            echo "$MATCHES" | while read -r res; do
              echo "Removing from state: $res"
              terraform state rm "$res" || true
            done
          else
            echo "No matching resources to remove."
          fi

      # -------- Phase A: create/repair base (no addons) --------
      - name: Plan base (no addons)
        if: steps.probe.outputs.exists == 'false'
        env:
          TF_VAR_install_addons: "false"
        run: terraform plan -lock-timeout=2m -out=tfplan_base

      - name: Apply base (no addons)
        if: steps.probe.outputs.exists == 'false'
        run: terraform apply -input=false -lock-timeout=2m -auto-approve tfplan_base

      - name: Allow runner IP to reach EKS API (post-base, idempotent)
        if: steps.probe.outputs.exists == 'false'
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail
          RUNNER_IP="$(curl -s https://checkip.amazonaws.com/ | tr -d '\r\n')"
          echo "Runner public IP: ${RUNNER_IP}"

          echo "Waiting for EKS cluster '${CLUSTER_NAME}' to become ACTIVE..."
          for i in $(seq 1 60); do
            STATUS="$(aws eks describe-cluster --region "${AWS_REGION}" --name "${CLUSTER_NAME}" --query 'cluster.status' --output text 2>/dev/null || echo "MISSING")"
            echo "  attempt ${i}: status=${STATUS}"
            [ "${STATUS}" = "ACTIVE" ] && break
            sleep 10
          done

          CUR_JSON="$(aws eks describe-cluster \
            --region "${AWS_REGION}" \
            --name "${CLUSTER_NAME}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' \
            --output json || echo '[]')"

          export CUR_JSON RUNNER_IP
          NEW_CSV="$(python3 -c 'import json,os; c=json.loads(os.environ.get("CUR_JSON") or "[]"); ip=os.environ["RUNNER_IP"].strip()+"/32"; print(",".join(c if ip in c else c+[ip]))')"
          echo "Updating cluster publicAccessCidrs: ${NEW_CSV}"
          aws eks update-cluster-config \
            --region "${AWS_REGION}" \
            --name "${CLUSTER_NAME}" \
            --resources-vpc-config publicAccessCidrs="${NEW_CSV}"

          ENDPOINT="$(aws eks describe-cluster --region "${AWS_REGION}" --name "${CLUSTER_NAME}" --query 'cluster.endpoint' --output text)"
          HOST="$(printf '%s\n' "$ENDPOINT" | sed -E 's#^https?://##; s#/.*$##')"
          echo "EKS endpoint host: ${HOST}"

          for i in $(seq 1 60); do
            if timeout 5 bash -lc "echo | openssl s_client -connect ${HOST}:443 -servername ${HOST} >/dev/null 2>&1"; then
              echo "EKS API reachable on ${HOST}:443"
              break
            fi
            echo "Waiting for EKS API to accept new CIDR... (${i}/60)"
            sleep 5
          done

      # -------- Phase B: converge full stack (addons enabled) --------
      - name: Plan full (addons enabled)
        env:
          TF_VAR_install_addons: "true"
        run: terraform plan -lock-timeout=2m -out=tfplan_full

      - name: Apply full (addons enabled)
        env:
          TF_VAR_install_addons: "true"
        run: terraform apply -input=false -lock-timeout=2m -auto-approve tfplan_full

      - name: Output
        run: terraform output -json || true
