name: Deploy Frontend to EKS

on:
  push:
    branches: ["main"]
    paths:
      - "frontend/**"
      - "infrastructure/docker/frontend/Dockerfile"
      - "infrastructure/k8s/frontend/deployment.yaml"
      - "infrastructure/k8s/ingress/frontend-ingress.yaml"
      - ".github/workflows/deploy_frontend.yml"
  workflow_dispatch:

concurrency:
  group: deploy-frontend-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: eu-central-1
  CLUSTER_NAME: nat20-eks
  PROJECT_NAME: nat20
  NAMESPACE: nat20
  ECR_REPO: nat20/frontend
  KUBECTL_TIMEOUT: 20s

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}

      - name: Ensure deps (jq, envsubst, openssl, curl)
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v jq >/dev/null 2>&1 || ! command -v envsubst >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq gettext-base
          fi
          command -v openssl >/dev/null 2>&1 || { echo "openssl missing"; exit 1; }
          command -v curl >/dev/null 2>&1 || { echo "curl missing"; exit 1; }

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set image variables
        id: vars
        shell: bash
        run: |
          set -euo pipefail
          echo "ECR_REGISTRY=${{ steps.ecr-login.outputs.registry }}" >> "$GITHUB_ENV"
          echo "IMAGE_URI=${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO }}:sha-${GITHUB_SHA}" >> "$GITHUB_ENV"

      - name: Build image
        shell: bash
        run: |
          set -euo pipefail
          docker build \
            -f infrastructure/docker/frontend/Dockerfile \
            -t "${IMAGE_URI}" \
            --label "org.opencontainers.image.revision=${GITHUB_SHA}" \
            --label "org.opencontainers.image.source=${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}" \
            .

      - name: Push image
        shell: bash
        run: |
          set -euo pipefail
          docker push "${IMAGE_URI}"

      - name: Fetch required parameters (SSM)
        id: ssm
        shell: bash
        run: |
          set -euo pipefail
          ORIGIN_CERT_ARN="$(aws ssm get-parameter --name /nat20/network/ORIGIN_CERT_ARN --query 'Parameter.Value' --output text)"
          ALB_FRONTEND_SG_ID="$(aws ssm get-parameter --name /nat20/network/ALB_FRONTEND_SG_ID --query 'Parameter.Value' --output text)"
          echo "ORIGIN_CERT_ARN=${ORIGIN_CERT_ARN}" >> "$GITHUB_ENV"
          echo "ALB_FRONTEND_SG_ID=${ALB_FRONTEND_SG_ID}" >> "$GITHUB_ENV"

      - name: Whitelist this runner IP for EKS API (merge, wait)
        id: open-eks
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail

          retry() {
            local tries="$1"; shift
            local delay="$1"; shift
            local n=1
            until "$@"; do
              if (( n >= tries )); then return 1; fi
              sleep "$delay"
              n=$((n+1))
            done
          }

          RUNNER_IP="$(curl -s https://checkip.amazonaws.com | tr -d '\n\r')"
          if [[ -z "${RUNNER_IP}" ]]; then
            echo "Failed to detect runner public IP" >&2
            exit 1
          fi
          RUNNER_CIDR="${RUNNER_IP}/32"
          echo "RUNNER_CIDR=${RUNNER_CIDR}" >> "$GITHUB_ENV"

          # Get current publicAccessCidrs (may be null or empty)
          ORIG_CIDRS_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json)"
          echo "ORIGINAL_CIDRS=${ORIG_CIDRS_JSON}" >> "$GITHUB_ENV"

          # Build updated list (unique) as CSV for CLI shorthand (cidr1,cidr2)
          UPDATED_JSON="$(jq -cn --arg ip "${RUNNER_CIDR}" --argjson cur "${ORIG_CIDRS_JSON:-null}" '
              ( ( ($cur // []) | map(tostring) ) + [$ip] ) | unique
          ')"
          UPDATED_CSV="$(jq -r 'join(",")' <<<"${UPDATED_JSON}")"

          if [[ -z "${UPDATED_CSV}" ]]; then
            echo "Failed to compute UPDATED_CSV" >&2
            exit 1
          fi

          echo "Updating cluster publicAccessCidrs to: ${UPDATED_CSV}"
          aws eks update-cluster-config \
            --name "${CLUSTER_NAME}" \
            --region "${AWS_REGION}" \
            --resources-vpc-config "publicAccessCidrs=${UPDATED_CSV}" >/dev/null

          # Wait for the control plane endpoint to accept TLS (up to ~5 min)
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.endpoint' --output text | sed -E 's#^https?://##')"
          echo "Waiting for EKS API endpoint TLS on ${ENDPOINT} ..."
          retry 30 10 bash -c "echo | openssl s_client -connect '${ENDPOINT}:443' -servername '${ENDPOINT}' -brief 2>/dev/null | grep -q 'Protocol  : TLS'"
          echo "EKS API is reachable."

      - name: Configure kubectl
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"
          kubectl version --client
          kubectl cluster-info --request-timeout="${KUBECTL_TIMEOUT}" || true
          kubectl get nodes -o wide --request-timeout="${KUBECTL_TIMEOUT}" || true

      - name: Ensure namespace exists
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..5}; do
            if kubectl apply -f infrastructure/k8s/namespaces/nat20.yaml --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply namespace..."
            sleep 10
          done

      - name: Apply frontend Deployment/Service
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..5}; do
            if kubectl apply -f infrastructure/k8s/frontend/deployment.yaml --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply deployment..."
            sleep 10
          done

      - name: Apply frontend Ingress (envsubst)
        shell: bash
        run: |
          set -euo pipefail
          export ORIGIN_CERT_ARN ALB_FRONTEND_SG_ID
          TMP_FILE="$(mktemp)"
          envsubst < infrastructure/k8s/ingress/frontend-ingress.yaml > "${TMP_FILE}"
          for i in {1..5}; do
            if kubectl apply -f "${TMP_FILE}" --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply ingress..."
            sleep 10
          done

      - name: Set image on Deployment
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" set image deployment/frontend frontend="${IMAGE_URI}" --record=true --request-timeout="${KUBECTL_TIMEOUT}"

      - name: Rollout status
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" rollout status deployment/frontend --timeout=300s

      - name: Debug on failure
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" get all -o wide --request-timeout="${KUBECTL_TIMEOUT}" || true
          kubectl -n "${NAMESPACE}" describe deployment frontend || true
          kubectl -n "${NAMESPACE}" get ingress frontend -o yaml || true
          kubectl -n "${NAMESPACE}" get events --sort-by=.lastTimestamp | tail -n 200 || true

      - name: Restore EKS API CIDRs (remove runner /32)
        if: always()
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail
          if [[ -z "${ORIGINAL_CIDRS:-}" || -z "${RUNNER_CIDR:-}" ]]; then
            echo "Skip restore: ORIGINAL_CIDRS or RUNNER_CIDR not set"
            exit 0
          fi

          CLEAN_JSON="$(jq -cn --arg ip "${RUNNER_CIDR}" --argjson cur "${ORIGINAL_CIDRS:-null}" '
              ( ($cur // []) | map(tostring) | map(select(. != $ip)) ) | unique
          ')"
          CLEAN_CSV="$(jq -r 'join(",")' <<<"${CLEAN_JSON}")"

          if [[ -z "${CLEAN_CSV}" ]]; then
            echo "Original CIDRs empty or unknown; skipping restore to avoid unsafe change."
            exit 0
          fi

          echo "Restoring cluster publicAccessCidrs to: ${CLEAN_CSV}"
          aws eks update-cluster-config \
            --name "${CLUSTER_NAME}" \
            --region "${AWS_REGION}" \
            --resources-vpc-config "publicAccessCidrs=${CLEAN_CSV}" >/dev/null
