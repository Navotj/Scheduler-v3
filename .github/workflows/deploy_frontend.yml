name: Deploy Frontend to EKS

on:
  push:
    branches: ["main"]
    paths:
      - "frontend/**"
      - "infrastructure/docker/frontend/Dockerfile"
      - "infrastructure/k8s/frontend/deployment.yaml"
      - "infrastructure/k8s/ingress/frontend-ingress.yaml"
      - ".github/workflows/deploy_frontend.yml"
  workflow_dispatch:

concurrency:
  group: deploy-frontend-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: eu-central-1
  CLUSTER_NAME: nat20-eks
  PROJECT_NAME: nat20
  NAMESPACE: nat20
  ECR_REPO: nat20/frontend
  KUBECTL_TIMEOUT: 30s

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}

      - name: Ensure deps (jq, envsubst, openssl, curl)
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq gettext-base
          command -v openssl >/dev/null 2>&1 || { echo "openssl missing"; exit 1; }
          command -v curl >/dev/null 2>&1 || { echo "curl missing"; exit 1; }

      - name: Login to Amazon ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v2

      - name: Set image variables
        id: vars
        shell: bash
        run: |
          set -euo pipefail
          echo "ECR_REGISTRY=${{ steps.ecr-login.outputs.registry }}" >> "$GITHUB_ENV"
          echo "IMAGE_URI=${{ steps.ecr-login.outputs.registry }}/${{ env.ECR_REPO }}:sha-${GITHUB_SHA}" >> "$GITHUB_ENV"

      - name: Build image
        shell: bash
        run: |
          set -euo pipefail
          docker build \
            -f infrastructure/docker/frontend/Dockerfile \
            -t "${IMAGE_URI}" \
            --label "org.opencontainers.image.revision=${GITHUB_SHA}" \
            --label "org.opencontainers.image.source=${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}" \
            .

      - name: Push image
        shell: bash
        run: |
          set -euo pipefail
          docker push "${IMAGE_URI}"

      - name: Fetch required parameters (SSM)
        id: ssm
        shell: bash
        run: |
          set -euo pipefail
          ORIGIN_CERT_ARN="$(aws ssm get-parameter --name /nat20/network/ORIGIN_CERT_ARN --query 'Parameter.Value' --output text)"
          ALB_FRONTEND_SG_ID="$(aws ssm get-parameter --name /nat20/network/ALB_FRONTEND_SG_ID --query 'Parameter.Value' --output text)"
          echo "ORIGIN_CERT_ARN=${ORIGIN_CERT_ARN}" >> "$GITHUB_ENV"
          echo "ALB_FRONTEND_SG_ID=${ALB_FRONTEND_SG_ID}" >> "$GITHUB_ENV"

      - name: Whitelist runner for EKS API (ensure public access; wait for update)
        id: open-eks
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail

          retry() {
            local tries="$1"; shift
            local delay="$1"; shift
            local n=1
            until "$@"; do
              if (( n >= tries )); then return 1; fi
              sleep "$delay"
              n=$((n+1))
            done
          }

          RUNNER_IP="$(curl -s https://checkip.amazonaws.com | tr -d '\n\r')"
          if [[ -z "${RUNNER_IP}" ]]; then
            echo "Failed to detect runner public IP" >&2
            exit 1
          fi
          RUNNER_CIDR="${RUNNER_IP}/32"

          # Read current endpointPublicAccess and CIDRs (compact JSON)
          DESC="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}")"
          EP_PUBLIC="$(jq -r '.cluster.resourcesVpcConfig.endpointPublicAccess' <<<"${DESC}")"
          CUR_JSON="$(jq -c '.cluster.resourcesVpcConfig.publicAccessCidrs // []' <<<"${DESC}")"

          echo "runner_cidr=${RUNNER_CIDR}" >> "$GITHUB_OUTPUT"
          echo "original_cidrs=${CUR_JSON}" >> "$GITHUB_OUTPUT"
          echo "original_ep=${EP_PUBLIC}" >> "$GITHUB_OUTPUT"

          # Build updated CIDR list always including runner
          UPDATED_JSON="$(jq -cn --arg ip "${RUNNER_CIDR}" --argjson cur "${CUR_JSON:-null}" '
              ( ( ($cur // []) | map(tostring) ) + [$ip] ) | unique
          ')"
          UPDATED_CSV="$(jq -r 'join(",")' <<<"${UPDATED_JSON}")"

          NEED_CIDR_UPDATE="$(jq -r --arg ip "${RUNNER_CIDR}" 'index($ip) | if . == null then "yes" else "no" end' <<<"${CUR_JSON}")"
          NEED_EP_ENABLE="$(test "${EP_PUBLIC}" = "false" && echo yes || echo no)"

          if [[ "${NEED_CIDR_UPDATE}" == "yes" || "${NEED_EP_ENABLE}" == "yes" ]]; then
            echo "Applying update: endpointPublicAccess=true, publicAccessCidrs=${UPDATED_CSV}"
            UPDATE_JSON="$(aws eks update-cluster-config \
              --name "${CLUSTER_NAME}" \
              --region "${AWS_REGION}" \
              --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${UPDATED_CSV}" \
              --output json)"
            UPDATE_ID="$(jq -r '.update.id' <<<"${UPDATE_JSON}")"
            if [[ -z "${UPDATE_ID}" || "${UPDATE_ID}" == "null" ]]; then
              echo "Failed to get update ID from update-cluster-config" >&2
              echo "${UPDATE_JSON}" >&2
              exit 1
            fi

            echo "Waiting for EKS update ${UPDATE_ID} to complete..."
            retry 120 5 bash -c '
              set -e
              ST=$(aws eks describe-update --name "'"${CLUSTER_NAME}"'" --update-id "'"${UPDATE_ID}"'" --region "'"${AWS_REGION}"'" --query "update.status" --output text)
              if [[ "$ST" == "Successful" ]]; then exit 0; fi
              if [[ "$ST" == "Failed" ]]; then
                aws eks describe-update --name "'"${CLUSTER_NAME}"'" --update-id "'"${UPDATE_ID}"'" --region "'"${AWS_REGION}"'" --output json
                exit 1
              fi
              exit 2
            '
          else
            echo "Runner already allowed and endpointPublicAccess already true; no update needed."
          fi

          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.endpoint' --output text | sed -E 's#^https?://##')"
          echo "Waiting for TLS at ${ENDPOINT}..."
          retry 24 5 bash -c "echo | openssl s_client -connect '${ENDPOINT}:443' -servername '${ENDPOINT}' -brief 2>/dev/null | grep -q '^Protocol  *:  *TLS'"

      - name: Configure kubectl
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"
          kubectl version --client
          kubectl cluster-info --request-timeout="${KUBECTL_TIMEOUT}" || true
          kubectl get nodes -o wide --request-timeout="${KUBECTL_TIMEOUT}" || true

      - name: Ensure namespace exists
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..5}; do
            if kubectl apply -f infrastructure/k8s/namespaces/nat20.yaml --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply namespace..."
            sleep 10
          done

      - name: Apply frontend Deployment/Service
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..5}; do
            if kubectl apply -f infrastructure/k8s/frontend/deployment.yaml --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply deployment..."
            sleep 10
          done

      - name: Apply frontend Ingress (envsubst)
        shell: bash
        run: |
          set -euo pipefail
          export ORIGIN_CERT_ARN ALB_FRONTEND_SG_ID
          TMP_FILE="$(mktemp)"
          envsubst < infrastructure/k8s/ingress/frontend-ingress.yaml > "${TMP_FILE}"
          for i in {1..5}; do
            if kubectl apply -f "${TMP_FILE}" --request-timeout="${KUBECTL_TIMEOUT}"; then
              break
            fi
            echo "Retry $i/5: waiting before re-apply ingress..."
            sleep 10
          done

      - name: Set image on Deployment
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" set image deployment/frontend frontend="${IMAGE_URI}" --record=true --request-timeout="${KUBECTL_TIMEOUT}"

      - name: Rollout status
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" rollout status deployment/frontend --timeout=300s

      - name: Debug on failure
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" get all -o wide --request-timeout="${KUBECTL_TIMEOUT}" || true
          kubectl -n "${NAMESPACE}" describe deployment frontend || true
          kubectl -n "${NAMESPACE}" get ingress frontend -o yaml || true
          kubectl -n "${NAMESPACE}" get events --sort-by=.lastTimestamp | tail -n 200 || true

      - name: Restore EKS API CIDRs (remove runner /32; restore endpointPublicAccess)
        if: always()
        id: restore
        shell: bash
        env:
          AWS_REGION: ${{ env.AWS_REGION }}
          CLUSTER_NAME: ${{ env.CLUSTER_NAME }}
          ORIGINAL_CIDRS: ${{ steps.open-eks.outputs.original_cidrs }}
          RUNNER_CIDR: ${{ steps.open-eks.outputs.runner_cidr }}
          ORIGINAL_EP: ${{ steps.open-eks.outputs.original_ep }}
        run: |
          set -euo pipefail
          # If originals are unknown, do not attempt restore.
          if [[ -z "${ORIGINAL_CIDRS:-}" || -z "${RUNNER_CIDR:-}" || -z "${ORIGINAL_EP:-}" ]]; then
            echo "Skip restore: missing ORIGINAL_CIDRS/RUNNER_CIDR/ORIGINAL_EP"
            exit 0
          fi

          # Clean CIDRs
          CLEAN_JSON="$(jq -cn --arg ip "${RUNNER_CIDR}" --argjson cur "${ORIGINAL_CIDRS:-null}" '
              ( ($cur // []) | map(tostring) | map(select(. != $ip)) ) | unique
          ')"
          CLEAN_CSV="$(jq -r 'join(",")' <<<"${CLEAN_JSON}")"

          if [[ "${ORIGINAL_EP}" == "false" ]]; then
            echo "Restoring endpointPublicAccess=false"
            aws eks update-cluster-config \
              --name "${CLUSTER_NAME}" \
              --region "${AWS_REGION}" \
              --resources-vpc-config "endpointPublicAccess=false" >/dev/null
          else
            # Restore EP=true and original CIDRs (minus runner)
            if [[ -n "${CLEAN_CSV}" ]]; then
              echo "Restoring CIDRs to: ${CLEAN_CSV}"
              aws eks update-cluster-config \
                --name "${CLUSTER_NAME}" \
                --region "${AWS_REGION}" \
                --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${CLEAN_CSV}" >/dev/null
            fi
          fi
