name: Deploy Frontend to EKS

on:
  push:
    branches: ["main"]
    paths:
      - "frontend/**"
      - ".github/workflows/deploy_frontend.yml"
      - "infrastructure/docker/frontend/Dockerfile"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    env:
      AWS_REGION: eu-central-1
      CLUSTER_NAME: nat20-eks

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Resolve ECR URI and SSM parameters (robust)
        id: resolve
        shell: bash
        run: |
          set -euo pipefail
          ECR_FRONTEND_URI="$(aws ssm get-parameter --name /nat20/ecr/FRONTEND_URI --query Parameter.Value --output text 2>/dev/null || true)"
          if [ -z "${ECR_FRONTEND_URI:-}" ] || [ "${ECR_FRONTEND_URI}" = "None" ]; then
            ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
            REPO_NAME="frontend"
            ECR_FRONTEND_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPO_NAME}"
            aws ecr describe-repositories --repository-names "${REPO_NAME}" >/dev/null 2>&1 || \
              aws ecr create-repository --repository-name "${REPO_NAME}" >/dev/null
          fi
          echo "ECR_FRONTEND_URI=${ECR_FRONTEND_URI}" >> "$GITHUB_ENV"

          ORIGIN_CERT_ARN="$(aws ssm get-parameter --name /nat20/network/ORIGIN_CERT_ARN --query Parameter.Value --output text 2>/dev/null || true)"
          ALB_FRONTEND_SG_ID="$(aws ssm get-parameter --name /nat20/network/ALB_FRONTEND_SG_ID --query Parameter.Value --output text 2>/dev/null || true)"
          if [ -z "${ORIGIN_CERT_ARN:-}" ] || [ "${ORIGIN_CERT_ARN}" = "None" ]; then
            echo "Missing SSM parameter: /nat20/network/ORIGIN_CERT_ARN" >&2; exit 1
          fi
          if [ -z "${ALB_FRONTEND_SG_ID:-}" ] || [ "${ALB_FRONTEND_SG_ID}" = "None" ]; then
            echo "Missing SSM parameter: /nat20/network/ALB_FRONTEND_SG_ID" >&2; exit 1
          fi
          echo "ORIGIN_CERT_ARN=${ORIGIN_CERT_ARN}" >> "$GITHUB_ENV"
          echo "ALB_FRONTEND_SG_ID=${ALB_FRONTEND_SG_ID}" >> "$GITHUB_ENV"
          echo "ORIGIN_HOST=origin.nat20scheduling.com" >> "$GITHUB_ENV"

      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push frontend image
        shell: bash
        run: |
          set -euo pipefail
          docker build -t "${ECR_FRONTEND_URI}:${GITHUB_SHA}" -f infrastructure/docker/frontend/Dockerfile .
          docker push "${ECR_FRONTEND_URI}:${GITHUB_SHA}"
          echo "FRONTEND_IMAGE=${ECR_FRONTEND_URI}:${GITHUB_SHA}" >> "$GITHUB_ENV"

      - name: Update image in k8s manifest
        shell: bash
        run: |
          set -euo pipefail
          sed -i "s#<ECR_URI_REPLACED_BY_CI>/frontend:\${GITHUB_SHA}#${ECR_FRONTEND_URI}:${GITHUB_SHA}#g" infrastructure/k8s/frontend/deployment.yaml

      # ðŸ” Lock EKS API access to this runner + your allowlist (from SSM)
      - name: Temporarily restrict EKS API to runner egress IP
        shell: bash
        run: |
          set -euo pipefail
          RUNNER_IP="$(curl -s https://checkip.amazonaws.com)/32"
          BASE_ALLOW="$(aws ssm get-parameter --name /nat20/network/EKS_API_ALLOWED_CIDRS --query Parameter.Value --output text 2>/dev/null || true)"
          if [ -n "${BASE_ALLOW:-}" ] && [ "${BASE_ALLOW}" != "None" ]; then
            CIDRS="${RUNNER_IP},${BASE_ALLOW}"
          else
            CIDRS="${RUNNER_IP}"
          fi
          aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --resources-vpc-config publicAccessCidrs="${CIDRS}"

      - name: Configure kubectl
        shell: bash
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"

      - name: Ensure namespace exists + enforce PSS (restricted)
        shell: bash
        run: |
          set -euo pipefail
          kubectl get ns nat20 >/dev/null 2>&1 || kubectl create ns nat20
          kubectl label ns nat20 \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite

      - name: Resolve ALB subnets for this cluster
        shell: bash
        run: |
          set -euo pipefail
          SUBNETS_CSV="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.resourcesVpcConfig.subnetIds' --output text | sed 's/\t/,/g')"
          [ -z "${SUBNETS_CSV:-}" ] && { echo "Could not resolve cluster subnets" >&2; exit 1; }
          echo "ALB_PUBLIC_SUBNET_IDS=${SUBNETS_CSV}" >> "$GITHUB_ENV"

      - name: Render ingress with cert/SG/host/subnets
        shell: bash
        run: |
          set -euo pipefail
          ORIGIN_CERT_ARN="${ORIGIN_CERT_ARN}" \
          ALB_FRONTEND_SG_ID="${ALB_FRONTEND_SG_ID}" \
          ORIGIN_HOST="${ORIGIN_HOST}" \
          ALB_PUBLIC_SUBNET_IDS="${ALB_PUBLIC_SUBNET_IDS}" \
          envsubst < infrastructure/k8s/ingress/frontend-ingress.yaml > /tmp/frontend-ingress.rendered.yaml

      - name: Apply frontend and ingress
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/frontend/deployment.yaml
          kubectl apply -f /tmp/frontend-ingress.rendered.yaml
          kubectl rollout status deployment/frontend -n nat20 --timeout=300s

      - name: Wait for Ingress hostname (ALB provisioning)
        id: alb
        shell: bash
        run: |
          set -euo pipefail
          for i in $(seq 1 90); do
            HOSTNAME="$(kubectl -n nat20 get ingress frontend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)"
            if [ -n "${HOSTNAME:-}" ] && [ "${HOSTNAME}" != "<no value>" ]; then break; fi
            echo "Waiting for Ingress ALB hostname... ($i/90)"; sleep 10
          done
          [ -z "${HOSTNAME:-}" ] || [ "${HOSTNAME}" = "<no value>" ] && { kubectl -n nat20 describe ingress frontend || true; exit 1; }
          echo "FRONTEND_ALB_DNS=${HOSTNAME}" >> "$GITHUB_ENV"
          echo "frontend_alb_dns=${HOSTNAME}" >> "$GITHUB_OUTPUT"

      # ðŸ” Restore long-term allowlist for EKS API (from SSM)
      - name: Restore EKS API CIDR allowlist
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          BASE_ALLOW="$(aws ssm get-parameter --name /nat20/network/EKS_API_ALLOWED_CIDRS --query Parameter.Value --output text 2>/dev/null || true)"
          if [ -n "${BASE_ALLOW:-}" ] && [ "${BASE_ALLOW}" != "None" ]; then
            aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --resources-vpc-config publicAccessCidrs="${BASE_ALLOW}"
          fi
