name: Deploy Mongo to EKS

on:
  workflow_dispatch: {}
  workflow_call: {}
  push:
    paths:
      - ".github/workflows/deploy_mongo.yml"
      - "infrastructure/k8s/mongo/**"
      - "infrastructure/k8s/externalsecrets/mongo-secrets.yaml"
      - "infrastructure/k8s/secret-stores/clustersecretstore.yaml"

permissions:
  id-token: write
  contents: read

concurrency:
  group: nat20-eks-ops
  cancel-in-progress: false

env:
  AWS_REGION: eu-central-1
  CLUSTER_NAME: nat20-eks
  PROJECT_NAME: nat20
  NAMESPACE: nat20
  KUBECTL_TIMEOUT: 45s
  AWS_RETRY_MODE: standard
  AWS_MAX_ATTEMPTS: 6

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install tooling
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq curl ca-certificates gettext-base
          sudo update-ca-certificates

      - name: kubeconfig
        shell: bash
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"
          kubectl version --client || true

      - name: "Preflight: API reachability (200/401/403 OK)"
        id: preflight
        shell: bash
        run: |
          set -euo pipefail
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.endpoint' --output text)"
          ok="false"
          for i in 1 2 3; do
            code="$(curl -k -sS -o /dev/null -w '%{http_code}' --connect-timeout 5 --max-time 10 "${ENDPOINT}/version" || echo 000)"
            if [[ "$code" == "200" || "$code" == "401" || "$code" == "403" ]]; then
              ok="true"; break
            fi
            sleep 5
          done
          echo "ok=${ok}" >> "$GITHUB_OUTPUT"

      - name: "Fallback: temporarily allow this runner CIDR"
        if: steps.preflight.outputs.ok != 'true'
        id: allow-runner
        shell: bash
        run: |
          set -euo pipefail
          RUNNER_CIDR="$(curl -s https://checkip.amazonaws.com | tr -d '\r\n')/32"
          echo "RUNNER_CIDR=${RUNNER_CIDR}" >> "$GITHUB_ENV"
          CUR_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json)"
          [[ -z "${CUR_JSON}" || "${CUR_JSON}" == "null" ]] && CUR_JSON='[]'
          NEW_CSV="$(printf '%s' "${CUR_JSON}" | jq -r --arg ip "$RUNNER_CIDR" '(. // []) + [$ip] | unique | join(",")')"
          UPDATE_ID="$(aws eks update-cluster-config --name "${CLUSTER_NAME}" --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${NEW_CSV}" --query 'update.id' --output text)"
          for _ in {1..30}; do
            PHASE="$(aws eks describe-update --name "${CLUSTER_NAME}" --update-id "${UPDATE_ID}" --query 'update.status' --output text)"
            [[ "${PHASE}" == "Successful" ]] && break
            [[ "${PHASE}" == "Failed" ]] && { echo "EKS update failed"; exit 1; }
            sleep 10
          done
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.endpoint' --output text)"
          code="$(curl -k -sS -o /dev/null -w '%{http_code}' --connect-timeout 5 --max-time 10 "${ENDPOINT}/version" || echo 000)"
          [[ "$code" == "200" || "$code" == "401" || "$code" == "403" ]]

      - name: Ensure CI EKS access (preflight)
        shell: bash
        env:
          GITHUB_CI_ROLE_NAME: nat20-github-ci
          GITHUB_CI_ROLE_ARN: ${{ secrets.GITHUB_CI_ROLE_ARN }}
        run: |
          set -euo pipefail
          CI_ARN="${GITHUB_CI_ROLE_ARN:-}"
          if [ -z "${CI_ARN}" ]; then
            CI_ARN="$(aws iam get-role --role-name "${GITHUB_CI_ROLE_NAME:-nat20-github-ci}" --query 'Role.Arn' --output text)"
          fi
          echo "CI role ARN: ${CI_ARN}"
          if ! aws eks describe-access-entry --cluster-name "${CLUSTER_NAME}" --principal-arn "${CI_ARN}" >/dev/null 2>&1; then
            aws eks create-access-entry --cluster-name "${CLUSTER_NAME}" --principal-arn "${CI_ARN}" --type STANDARD --username github-ci >/dev/null
          fi
          if [ "$(aws eks list-associated-access-policies --cluster-name "${CLUSTER_NAME}" --principal-arn "${CI_ARN}" \
                --query "associatedAccessPolicies[?policyArn=='arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy'] | length(@)" --output text)" != "1" ]; then
            aws eks associate-access-policy --cluster-name "${CLUSTER_NAME}" --principal-arn "${CI_ARN}" \
              --policy-arn arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy --access-scope type=cluster >/dev/null
          fi

      - name: Ensure namespaces + PSS labels
        shell: bash
        run: |
          set -euo pipefail
          kubectl get ns "${NAMESPACE}" >/dev/null 2>&1 || kubectl create ns "${NAMESPACE}"
          kubectl get ns externalsecrets >/dev/null 2>&1 || kubectl create ns externalsecrets
          kubectl label ns "${NAMESPACE}" \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite || true

      - name: Ensure External Secrets CRDs (pinned)
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply --server-side -f https://raw.githubusercontent.com/external-secrets/external-secrets/v0.19.2/deploy/crds/bundle.yaml
          kubectl wait --for=condition=Established crd clustersecretstores.external-secrets.io --timeout=120s
          kubectl wait --for=condition=Established crd secretstores.external-secrets.io --timeout=120s
          kubectl wait --for=condition=Established crd externalsecrets.external-secrets.io --timeout=120s

      - name: Ensure aws-ebs-csi-driver addon ACTIVE (with IRSA role)
        shell: bash
        env:
          EBS_ROLE_NAME: nat20-ebs-csi-irsa
        run: |
          set -euo pipefail
          ROLE_ARN="$(aws iam get-role --role-name "${EBS_ROLE_NAME}" --query 'Role.Arn' --output text 2>/dev/null || true)"
          if [[ -z "${ROLE_ARN}" || "${ROLE_ARN}" == "None" ]]; then
            echo "EBS CSI IRSA role '${EBS_ROLE_NAME}' not found. Make sure Terraform created it."; exit 1
          fi
          if ! aws eks describe-addon --cluster-name "${CLUSTER_NAME}" --addon-name aws-ebs-csi-driver >/dev/null 2>&1; then
            aws eks create-addon --cluster-name "${CLUSTER_NAME}" --addon-name aws-ebs-csi-driver \
              --service-account-role-arn "${ROLE_ARN}" --resolve-conflicts OVERWRITE >/dev/null
          else
            aws eks update-addon --cluster-name "${CLUSTER_NAME}" --addon-name aws-ebs-csi-driver \
              --service-account-role-arn "${ROLE_ARN}" --resolve-conflicts OVERWRITE >/dev/null || true
          fi
          for i in {1..60}; do
            ST="$(aws eks describe-addon --cluster-name "${CLUSTER_NAME}" --addon-name aws-ebs-csi-driver --query 'addon.status' --output text || true)"
            [[ "${ST}" == "ACTIVE" ]] && { echo "aws-ebs-csi-driver ACTIVE"; break; }
            [[ "${ST}" == "CREATE_FAILED" || "${ST}" == "DEGRADED" ]] && { aws eks describe-addon --cluster-name "${CLUSTER_NAME}" --addon-name aws-ebs-csi-driver; exit 1; }
            [[ $i -eq 60 ]] && { echo "aws-ebs-csi-driver not ACTIVE in time (last=${ST})"; exit 1; }
            sleep 5
          done

      - name: Ensure eks-pod-identity-agent is ACTIVE
        shell: bash
        run: |
          set -euo pipefail
          if ! aws eks describe-addon --cluster-name "${CLUSTER_NAME}" --addon-name eks-pod-identity-agent >/dev/null 2>&1; then
            aws eks create-addon --cluster-name "${CLUSTER_NAME}" --addon-name eks-pod-identity-agent --resolve-conflicts OVERWRITE >/dev/null
          else
            aws eks update-addon --cluster-name "${CLUSTER_NAME}" --addon-name eks-pod-identity-agent --resolve-conflicts OVERWRITE >/dev/null || true
          fi
          for i in {1..60}; do
            ST="$(aws eks describe-addon --cluster-name "${CLUSTER_NAME}" --addon-name eks-pod-identity-agent --query 'addon.status' --output text || true)"
            [[ "${ST}" == "ACTIVE" ]] && { echo "eks-pod-identity-agent ACTIVE"; break; }
            [[ $i -eq 60 ]] && { echo "eks-pod-identity-agent not ACTIVE in time (last=${ST})"; exit 1; }
            sleep 5
          done

      - name: Ensure gp3 StorageClass exists
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/storageclasses/gp3.yaml
          kubectl get sc gp3

      - name: Apply ClusterSecretStore + Mongo ExternalSecret
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/secret-stores/clustersecretstore.yaml
          kubectl apply -n "${NAMESPACE}" -f infrastructure/k8s/externalsecrets/mongo-secrets.yaml
          for i in {1..36}; do
            kubectl -n "${NAMESPACE}" get secret mongo-root >/dev/null 2>&1 && break
            sleep 5
          done
          kubectl -n "${NAMESPACE}" get secret mongo-root >/dev/null 2>&1 || { echo "mongo-root Secret not materialized"; exit 1; }

      - name: Deploy Mongo services + StatefulSet (immutable-safe)
        shell: bash
        run: |
          set -euo pipefail
          MANIFEST="infrastructure/k8s/mongo/statefulset.yaml"
          RAW_JSON="$(kubectl apply --dry-run=client -f "${MANIFEST}" -o json)"
          ITEMS_JSON="$(echo "${RAW_JSON}" | jq -c 'if .kind=="List" then .items else [.] end')"
          echo "${ITEMS_JSON}" | jq -c '.[] | select(.kind=="Service")' | while read -r SVC; do
            echo "${SVC}" | kubectl -n "${NAMESPACE}" apply -f -
          done
          DESIRED_STS="$(echo "${ITEMS_JSON}" | jq '.[] | select(.kind=="StatefulSet")')"
          [[ -n "${DESIRED_STS}" && "${DESIRED_STS}" != "null" ]]
          DES_SVC_NAME="$(echo "${DESIRED_STS}" | jq -r '.spec.serviceName')"
          DES_SELECTOR="$(echo "${DESIRED_STS}" | jq -c '.spec.selector')"
          DES_VCT="$(echo "${DESIRED_STS}" | jq -c '.spec.volumeClaimTemplates')"
          RECREATE=0
          if kubectl -n "${NAMESPACE}" get sts mongo >/dev/null 2>&1; then
            CUR_JSON="$(kubectl -n "${NAMESPACE}" get sts mongo -o json)"
            CUR_SVC_NAME="$(echo "${CUR_JSON}" | jq -r '.spec.serviceName')"
            CUR_SELECTOR="$(echo "${CUR_JSON}" | jq -c '.spec.selector')"
            CUR_VCT="$(echo "${CUR_JSON}" | jq -c '.spec.volumeClaimTemplates')"
            if [[ "${CUR_SVC_NAME}" != "${DES_SVC_NAME}" || "${CUR_SELECTOR}" != "${DES_SELECTOR}" || "${CUR_VCT}" != "${DES_VCT}" ]]; then
              RECREATE=1
            fi
          fi
          if [[ $RECREATE -eq 1 ]]; then
            echo "Detected immutable field change; recreating StatefulSet 'mongo'..."
            kubectl -n "${NAMESPACE}" scale sts mongo --replicas=0 || true
            kubectl -n "${NAMESPACE}" delete sts mongo --wait=true
          fi
          echo "${DESIRED_STS}" | kubectl -n "${NAMESPACE}" apply -f -

      - name: Wait for PVC bound and Pod ready
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..30}; do
            PHASE="$(kubectl -n "${NAMESPACE}" get pvc mongo-data-mongo-0 -o jsonpath='{.status.phase}' 2>/dev/null || echo '')"
            if [[ "${PHASE}" == "Bound" ]]; then
              echo "PVC Bound."; break
            fi
            [[ $i -eq 30 ]] && { echo "PVC didn't bind in time."; kubectl -n "${NAMESPACE}" describe pvc mongo-data-mongo-0 || true; exit 1; }
            sleep 4
          done
          kubectl -n "${NAMESPACE}" rollout status statefulset/mongo --timeout=8m

      - name: Output Mongo service and pods
        shell: bash
        run: |
          set -euo pipefail
          kubectl get sc gp3
          kubectl -n "${NAMESPACE}" get pvc -l app=mongo -o wide || true
          kubectl -n "${NAMESPACE}" get svc mongo -o wide || true
          kubectl -n "${NAMESPACE}" get pods -l app=mongo -o wide || true

      - name: "Cleanup: remove temporary runner CIDR from EKS API"
        if: always() && steps.preflight.outputs.ok != 'true'
        shell: bash
        run: |
          set -euo pipefail
          if [[ -z "${RUNNER_CIDR:-}" ]]; then
            echo "No RUNNER_CIDR set; skipping cleanup."; exit 0
          fi
          CUR_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json)"
          [[ -z "${CUR_JSON}" || "${CUR_JSON}" == "null" ]] && CUR_JSON='[]'
          REST_CSV="$(printf '%s' "${CUR_JSON}" | jq -r --arg ip "$RUNNER_CIDR" '(. // []) | map(select(. != $ip)) | unique | join(",")')"
          UPDATE_ID="$(aws eks update-cluster-config --name "${CLUSTER_NAME}" --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${REST_CSV}" --query 'update.id' --output text)"
          for _ in {1..30}; do
            PHASE="$(aws eks describe-update --name "${CLUSTER_NAME}" --update-id "${UPDATE_ID}" --query 'update.status' --output text)"
            [[ "${PHASE}" == "Successful" ]] && break
            [[ "${PHASE}" == "Failed" ]] && { echo "Cleanup EKS update failed"; exit 1; }
            sleep 10
          done

      - name: "On failure: collect diagnostics"
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          echo "=== nodes ==="
          kubectl get nodes -o wide || true
          echo "=== ns objects (nat20) ==="
          kubectl -n "${NAMESPACE}" get all -o wide || true
          echo "=== events (last 300) ==="
          kubectl -n "${NAMESPACE}" get events --sort-by=.lastTimestamp | tail -n 300 || true
          echo "=== sts describe ==="
          kubectl -n "${NAMESPACE}" describe sts mongo || true
          echo "=== pod logs (last 200) ==="
          for p in $(kubectl -n "${NAMESPACE}" get pods -l app=mongo -o name 2>/dev/null | sed 's|pod/||'); do
            echo "--- $p ---"
            kubectl -n "${NAMESPACE}" logs "$p" --tail=200 2>/dev/null || true
          done
