name: Deploy Mongo to EKS

on:
  push:
    branches: ["main"]
    paths:
      - ".github/workflows/deploy_mongo.yml"
      - "infrastructure/k8s/mongo/**"
      - "infrastructure/k8s/externalsecrets/mongo-secrets.yaml"
      - "infrastructure/k8s/secret-stores/clustersecretstore.yaml"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: eu-central-1
      CLUSTER_NAME: nat20-eks

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Capture current EKS API CIDRs + endpoint
        shell: bash
        run: |
          set -euo pipefail
          ORIG="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.endpoint' --output text)"
          echo "ORIGINAL_EKS_API_CIDRS=${ORIG}" >> "$GITHUB_ENV"
          echo "EKS_ENDPOINT=${ENDPOINT}" >> "$GITHUB_ENV"

      - name: Temporarily allow runner IP for EKS API (union + wait)
        shell: bash
        run: |
          set -euo pipefail
          RUNNER_IP="$(curl -s https://checkip.amazonaws.com)/32"
          CURRENT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
          if [ -n "${CURRENT}" ] && [ "${CURRENT}" != "None" ]; then
            CIDRS="${RUNNER_IP},${CURRENT}"
          else
            CIDRS="${RUNNER_IP}"
          fi
          CIDRS="$(tr ',' '\n' <<< "${CIDRS}" | awk 'NF{print $0}' | sort -u | paste -sd, -)"
          if [ "${CURRENT}" != "${CIDRS}" ]; then
            UPDATE_ID="$(aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --resources-vpc-config publicAccessCidrs="${CIDRS}" \
              --query 'update.id' --output text 2>/tmp/eks_update.err || true)"
            if [ -z "${UPDATE_ID}" ] || [ "${UPDATE_ID}" = "None" ]; then
              if ! grep -qi "already at the desired configuration" /tmp/eks_update.err; then
                cat /tmp/eks_update.err >&2
                exit 1
              fi
            else
              for i in $(seq 1 60); do
                STATUS="$(aws eks describe-update --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
                  --update-id "${UPDATE_ID}" --query 'update.status' --output text || true)"
                [ "${STATUS}" = "Successful" ] && break
                if [ "${STATUS}" = "Failed" ] || [ "${STATUS}" = "Cancelled" ]; then
                  aws eks describe-update --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
                    --update-id "${UPDATE_ID}" --output json >&2
                  exit 1
                fi
                sleep 5
              done
            fi
          fi
          HOST="$(echo "${EKS_ENDPOINT}" | sed -E 's#https?://##g')"
          for i in $(seq 1 60); do
            if timeout 5 bash -lc "exec 3<>/dev/tcp/${HOST}/443" 2>/dev/null; then
              exec 3>&-
              break
            fi
            sleep 2
          done

      - name: Configure kubectl (with retries)
        shell: bash
        run: |
          set -euo pipefail
          for i in 1 2 3; do
            if aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"; then
              break
            fi
            sleep $((i*5))
            [ $i -eq 3 ] && exit 1
          done
          for i in $(seq 1 30); do
            if kubectl --request-timeout=10s version --short >/dev/null 2>&1; then
              break
            fi
            sleep 3
          done

      - name: Ensure namespaces exist + enforce PSS (restricted)
        shell: bash
        run: |
          set -euo pipefail
          kubectl get ns nat20 >/dev/null 2>&1 || kubectl create ns nat20
          kubectl get ns externalsecrets >/dev/null 2>&1 || kubectl create ns externalsecrets
          kubectl label ns nat20 \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite || true

      - name: Ensure External Secrets CRDs (server-side, pinned, retries)
        shell: bash
        run: |
          set -euo pipefail
          for i in 1 2 3; do
            if kubectl apply --server-side -f https://raw.githubusercontent.com/external-secrets/external-secrets/v0.19.2/deploy/crds/bundle.yaml; then
              break
            fi
            sleep $((i*5))
            [ $i -eq 3 ] && exit 1
          done
          kubectl wait --for=condition=Established crd clustersecretstores.external-secrets.io --timeout=180s
          kubectl wait --for=condition=Established crd secretstores.external-secrets.io --timeout=180s
          kubectl wait --for=condition=Established crd externalsecrets.external-secrets.io --timeout=180s

      - name: Preflight check required SSM params (diagnostic)
        shell: bash
        run: |
          set -euo pipefail
          KEYS=(/nat20/mongo/USER /nat20/mongo/PASSWORD)
          MISSING=0
          for KEY in "${KEYS[@]}"; do
            if ! aws ssm get-parameter --region "${AWS_REGION}" --name "$KEY" >/dev/null 2>&1; then
              echo "Missing SSM parameter: $KEY" >&2
              MISSING=$((MISSING+1))
            fi
          done
          [ $MISSING -eq 0 ] || { echo "Required SSM parameters missing; aborting." >&2; exit 1; }

      - name: Apply ClusterSecretStore and Mongo ExternalSecret (robust)
        shell: bash
        run: |
          set -euo pipefail
          k_apply() {
            local file="$1"
            local tries=0
            until kubectl apply --request-timeout=45s -f "$file"; do
              tries=$((tries+1))
              if [ $tries -ge 4 ]; then
                kubectl apply --request-timeout=45s --validate=false -f "$file"
                break
              fi
              sleep $((tries*3))
            done
          }
          k_apply infrastructure/k8s/secret-stores/clustersecretstore.yaml
          k_apply infrastructure/k8s/externalsecrets/mongo-secrets.yaml

          kubectl -n nat20 wait --for=condition=Ready externalsecret.external-secrets.io/mongo-root --timeout=300s
          for i in $(seq 1 60); do
            kubectl -n nat20 get secret mongo-root >/dev/null 2>&1 && break
            sleep 5
          done

      - name: Deploy MongoDB Services + StatefulSet (immutable-safe)
        shell: bash
        run: |
          set -euo pipefail
          MANIFEST="infrastructure/k8s/mongo/statefulset.yaml"

          # Ensure 'mongo' Service is ClusterIP (not headless)
          if kubectl -n nat20 get svc mongo >/dev/null 2>&1; then
            CIP="$(kubectl -n nat20 get svc mongo -o jsonpath='{.spec.clusterIP}' || true)"
            if [ "${CIP}" = "None" ]; then
              kubectl -n nat20 delete svc mongo
            fi
          fi

          RAW_JSON="$(kubectl apply -n nat20 --dry-run=client -f "${MANIFEST}" -o json)"
          ITEMS_JSON="$(echo "${RAW_JSON}" | jq -c 'if .kind=="List" then .items else [.] end')"

          echo "${ITEMS_JSON}" | jq -c '.[] | select(.kind=="Service")' | while read -r SVC; do
            echo "${SVC}" | kubectl -n nat20 apply -f -
          done

          DESIRED_STS="$(echo "${ITEMS_JSON}" | jq '.[] | select(.kind=="StatefulSet")')"
          [ -n "${DESIRED_STS}" ] && [ "${DESIRED_STS}" != "null" ] || { echo "ERROR: No StatefulSet in ${MANIFEST}" >&2; exit 1; }

          DES_SVC_NAME="$(echo "${DESIRED_STS}" | jq -r '.spec.serviceName')"
          DES_SELECTOR="$(echo "${DESIRED_STS}" | jq -c '.spec.selector')"
          DES_VCT="$(echo "${DESIRED_STS}" | jq -c '.spec.volumeClaimTemplates')"

          if kubectl -n nat20 get sts mongo >/dev/null 2>&1; then
            CUR_JSON="$(kubectl -n nat20 get sts mongo -o json)"
            CUR_SVC_NAME="$(echo "${CUR_JSON}" | jq -r '.spec.serviceName')"
            CUR_SELECTOR="$(echo "${CUR_JSON}" | jq -c '.spec.selector')"
            CUR_VCT="$(echo "${CUR_JSON}" | jq -c '.spec.volumeClaimTemplates')"

            NEED_RECREATE=0
            [ "${CUR_SVC_NAME}" != "${DES_SVC_NAME}" ] && NEED_RECREATE=1
            [ "${CUR_SELECTOR}" != "${DES_SELECTOR}" ] && NEED_RECREATE=1
            [ "${CUR_VCT}" != "${DES_VCT}" ] && NEED_RECREATE=1

            if [ $NEED_RECREATE -eq 1 ]; then
              kubectl -n nat20 scale sts mongo --replicas=0 || true
              for i in $(seq 1 60); do
                CNT="$(kubectl -n nat20 get pods -l app=mongo --no-headers 2>/dev/null | wc -l | tr -d ' ')"
                [ "${CNT}" = "0" ] && break
                sleep 5
              done
              kubectl -n nat20 delete sts mongo --wait=true
            fi
          fi

          echo "${DESIRED_STS}" | kubectl -n nat20 apply -f -
          kubectl -n nat20 rollout status statefulset/mongo --timeout=600s

      - name: Output Mongo resources
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n nat20 get pvc -o wide || true
          kubectl -n nat20 get pv -o wide || true
          kubectl -n nat20 get svc mongo -o wide || true
          kubectl -n nat20 get svc mongo-hl -o wide || true
          kubectl -n nat20 get sts mongo -o wide || true
          kubectl -n nat20 get pods -l app=mongo -o wide || true

      - name: Debug on failure (describe + logs + events)
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n nat20 describe sts mongo || true
          kubectl -n nat20 describe pods -l app=mongo || true
          kubectl -n nat20 logs sts/mongo --tail=200 || true
          kubectl -n nat20 get events --sort-by=.lastTimestamp | tail -n 200 || true

      - name: Restore EKS API CIDRs to original (idempotent)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${ORIGINAL_EKS_API_CIDRS:-}" ]; then
            CURRENT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
            if [ "${CURRENT}" != "${ORIGINAL_EKS_API_CIDRS}" ]; then
              if ! aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
                --resources-vpc-config publicAccessCidrs="${ORIGINAL_EKS_API_CIDRS}" 2>/tmp/eks_restore.err; then
                if ! grep -qi "already at the desired configuration" /tmp/eks_restore.err; then
                  cat /tmp/eks_restore.err >&2
                  exit 1
                fi
              fi
            fi
          fi
