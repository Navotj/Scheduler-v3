name: Deploy Mongo to EKS

on:
  push:
    branches: ["main"]
    paths:
      - ".github/workflows/deploy_mongo.yml"
      - "infrastructure/k8s/mongo/**"
      - "infrastructure/k8s/externalsecrets/mongo-secrets.yaml"
      - "infrastructure/k8s/secret-stores/clustersecretstore.yaml"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: eu-central-1
      CLUSTER_NAME: nat20-eks

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Capture current EKS API CIDRs
        shell: bash
        run: |
          set -euo pipefail
          ORIG="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
          echo "ORIGINAL_EKS_API_CIDRS=${ORIG}" >> "$GITHUB_ENV"

      - name: Temporarily restrict EKS API to runner egress IP (idempotent)
        shell: bash
        run: |
          set -euo pipefail
          RUNNER_IP="$(curl -s https://checkip.amazonaws.com)/32"
          CURRENT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
          if [ "${CURRENT}" = "${RUNNER_IP}" ]; then
            echo "EKS API publicAccessCidrs already ${RUNNER_IP}; skipping update."
          else
            if aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --resources-vpc-config publicAccessCidrs="${RUNNER_IP}" 2>/tmp/eks_update.err; then
              echo "Set publicAccessCidrs=${RUNNER_IP}"
            else
              if grep -qi "already at the desired configuration" /tmp/eks_update.err; then
                echo "No-op: cluster already at desired configuration."
              else
                cat /tmp/eks_update.err >&2
                exit 1
              fi
            fi
          fi

      - name: Configure kubectl
        shell: bash
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"

      - name: Ensure namespaces exist + enforce PSS (restricted)
        shell: bash
        run: |
          set -euo pipefail
          kubectl get ns nat20 >/dev/null 2>&1 || kubectl create ns nat20
          kubectl get ns externalsecrets >/dev/null 2>&1 || kubectl create ns externalsecrets
          kubectl label ns nat20 \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite || true

      - name: Ensure External Secrets CRDs (server-side, pinned)
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply --server-side -f https://raw.githubusercontent.com/external-secrets/external-secrets/v0.19.2/deploy/crds/bundle.yaml
          kubectl wait --for=condition=Established crd clustersecretstores.external-secrets.io --timeout=180s
          kubectl wait --for=condition=Established crd secretstores.external-secrets.io --timeout=180s
          kubectl wait --for=condition=Established crd externalsecrets.external-secrets.io --timeout=180s

      - name: Preflight check required SSM params (diagnostic)
        shell: bash
        run: |
          set -euo pipefail
          : "${AWS_REGION:?AWS_REGION not set}"
          KEYS=(/nat20/mongo/USER /nat20/mongo/PASSWORD)
          MISSING=0
          for KEY in "${KEYS[@]}"; do
            echo "=== $KEY ==="
            if aws ssm get-parameter --region "$AWS_REGION" --name "$KEY" >/dev/null 2>"/tmp/err.$$"; then
              echo "OK $KEY"
            else
              echo "FAIL $KEY"
              cat /tmp/err.$$ >&2 || true
              MISSING=$((MISSING+1))
            fi
          done
          rm -f /tmp/err.$$
          [ $MISSING -eq 0 ] || { echo "Required SSM parameters missing; aborting."; exit 1; }

      - name: Apply ClusterSecretStore and Mongo ExternalSecret
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/secret-stores/clustersecretstore.yaml
          kubectl apply -n nat20 -f infrastructure/k8s/externalsecrets/mongo-secrets.yaml
          kubectl -n nat20 wait --for=condition=Ready externalsecret.external-secrets.io/mongo-root --timeout=300s
          for i in $(seq 1 60); do
            if kubectl -n nat20 get secret mongo-root >/dev/null 2>&1; then
              echo "mongo-root Secret exists"
              break
            fi
            echo "Waiting for mongo-root Secret... ($i/60)"
            sleep 5
          done

      - name: Deploy MongoDB StatefulSet (persistent)
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -n nat20 -f infrastructure/k8s/mongo/statefulset.yaml
          kubectl -n nat20 rollout status statefulset/mongo --timeout=600s

      - name: Output Mongo service
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n nat20 get svc mongo -o wide || true

      - name: Restore EKS API CIDRs to original (idempotent)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${ORIGINAL_EKS_API_CIDRS:-}" ]; then
            CURRENT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output text | sed 's/\t/,/g')"
            if [ "${CURRENT}" = "${ORIGINAL_EKS_API_CIDRS}" ]; then
              echo "Already at ORIGINAL_EKS_API_CIDRS (${ORIGINAL_EKS_API_CIDRS}); skipping restore."
            else
              if aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
                --resources-vpc-config publicAccessCidrs="${ORIGINAL_EKS_API_CIDRS}" 2>/tmp/eks_restore.err; then
                echo "Restored publicAccessCidrs=${ORIGINAL_EKS_API_CIDRS}"
              else
                if grep -qi "already at the desired configuration" /tmp/eks_restore.err; then
                  echo "No-op: cluster already at desired configuration."
                else
                  cat /tmp/eks_restore.err >&2
                  exit 1
                fi
              fi
            fi
          else
            echo "No ORIGINAL_EKS_API_CIDRS captured; leaving current setting in place."
          fi
