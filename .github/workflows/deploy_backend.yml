name: Deploy Backend

on:
  workflow_dispatch: {}
  push:
    branches: [ "main" ]
    paths:
      - 'backend/**'
      - '.github/workflows/deploy_backend.yml'

concurrency:
  group: deploy-backend-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  APP_PREFIX: ${{ vars.APP_PREFIX }}
  AWS_REGION: ${{ vars.AWS_REGION }}
  BACKEND_SSM_TARGET_KEY:   tag:Name
  BACKEND_SSM_TARGET_VALUE: ${{ vars.APP_PREFIX }}-backend

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    steps:
      - name: checkout
        uses: actions/checkout@v5

      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: ensure aws cli
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v aws >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y unzip >/dev/null
            curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o awscliv2.zip
            unzip -q awscliv2.zip
            sudo ./aws/install
          fi
          aws --version

      - name: sanity checks
        shell: bash
        run: |
          set -euo pipefail
          [[ -n "${APP_PREFIX}" ]] || { echo "APP_PREFIX is empty"; exit 1; }
          [[ -n "${AWS_REGION}"  ]] || { echo "AWS_REGION is empty";  exit 1; }
          [[ -d "backend/app" ]] || { echo "missing: backend/app"; exit 1; }
          [[ -f "backend/scheduler.service" ]] || { echo "missing: backend/scheduler.service"; exit 1; }

          ARTIFACT_BUCKET="${APP_PREFIX}-artifacts"
          echo "ARTIFACT_BUCKET=${ARTIFACT_BUCKET}" >> "$GITHUB_ENV"

          MATCHING_INSTANCES=$(aws ssm describe-instance-information \
            --filters "Key=tag:Name,Values=${BACKEND_SSM_TARGET_VALUE}" \
            --query "InstanceInformationList[].InstanceId" --output text || true)
          if [[ -z "${MATCHING_INSTANCES}" || "${MATCHING_INSTANCES}" == "None" ]]; then
            echo "WARN: No SSM-managed instances currently match ${BACKEND_SSM_TARGET_KEY}=${BACKEND_SSM_TARGET_VALUE}" >&2
          else
            echo "Found SSM instances: ${MATCHING_INSTANCES}"
          fi

      - name: ensure artifact bucket exists
        shell: bash
        run: |
          set -euo pipefail
          : "${ARTIFACT_BUCKET:?missing}"
          : "${AWS_REGION:?missing}"

          if aws s3api head-bucket --bucket "${ARTIFACT_BUCKET}" 2>/dev/null; then
            echo "Bucket ${ARTIFACT_BUCKET} exists"
          else
            echo "Creating bucket ${ARTIFACT_BUCKET} in ${AWS_REGION}"
            if [[ "${AWS_REGION}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "${ARTIFACT_BUCKET}"
            else
              aws s3api create-bucket --bucket "${ARTIFACT_BUCKET}" \
                --create-bucket-configuration LocationConstraint="${AWS_REGION}"
            fi
          fi

          aws s3api put-bucket-encryption --bucket "${ARTIFACT_BUCKET}" --server-side-encryption-configuration '{
            "Rules":[{"ApplyServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]
          }'
          aws s3api put-public-access-block --bucket "${ARTIFACT_BUCKET}" --public-access-block-configuration '{
            "BlockPublicAcls": true,
            "IgnorePublicAcls": true,
            "BlockPublicPolicy": true,
            "RestrictPublicBuckets": true
          }'
          aws s3api put-bucket-ownership-controls --bucket "${ARTIFACT_BUCKET}" --ownership-controls '{
            "Rules":[{"ObjectOwnership":"BucketOwnerEnforced"}]
          }' || true
          aws s3api put-bucket-versioning --bucket "${ARTIFACT_BUCKET}" --versioning-configuration Status=Enabled

      - name: package backend (app + service)
        working-directory: ${{ github.workspace }}
        shell: bash
        run: |
          set -euo pipefail
          test -d backend/app
          test -f backend/scheduler.service
          tar -czf backend_release.tgz \
            --owner=0 --group=0 \
            -C backend app scheduler.service
          ls -lh backend_release.tgz

      - name: upload artifact to s3
        shell: bash
        run: |
          set -euo pipefail
          OBJECT_KEY="releases/backend_release.tgz"
          aws s3 cp backend_release.tgz "s3://${ARTIFACT_BUCKET}/${OBJECT_KEY}" --sse AES256 --only-show-errors
          echo "OBJECT_KEY=${OBJECT_KEY}" >> "$GITHUB_ENV"

      - name: deploy on instances via ssm
        shell: bash
        run: |
          set -euo pipefail

          INSTANCE_IDS=$(aws ssm describe-instance-information \
            --filters "Key=tag:Name,Values=${BACKEND_SSM_TARGET_VALUE}" \
            --query "InstanceInformationList[].InstanceId" --output text || true)
          echo "Targeting instances: ${INSTANCE_IDS:-<none>}"

          CMD=$(cat <<'EOS'
          set -euo pipefail
          : "${ARTIFACT_BUCKET:?missing}"
          : "${OBJECT_KEY:?missing}"
          : "${AWS_REGION:?missing}"
          ARTIFACT_S3="s3://${ARTIFACT_BUCKET}/${OBJECT_KEY}"
          WORKDIR="/opt/app"
          TMP_TGZ="/tmp/backend_release.tgz"
          UNIT_SRC="/tmp/scheduler.service"
          UNIT_DST="/etc/systemd/system/scheduler.service"

          install -d -m 0755 "${WORKDIR}"
          aws s3 cp "${ARTIFACT_S3}" "${TMP_TGZ}"
          rm -rf /tmp/app "${UNIT_SRC}" || true
          tar -xzf "${TMP_TGZ}" -C /tmp

          # preserve existing .env (managed by user_data), update code only
          find "${WORKDIR}" -mindepth 1 -maxdepth 1 -not -name '.env' -exec rm -rf -- {} +

          shopt -s dotglob
          cp -a /tmp/app/* "${WORKDIR}/" || true
          shopt -u dotglob
          chown -R ec2-user:ec2-user "${WORKDIR}" || true

          # install production deps
          cd "${WORKDIR}"
          export NODE_ENV=production
          if [[ -f package-lock.json ]]; then
            npm ci --omit=dev
          else
            npm install --omit=dev
          fi

          install -D -m 0644 "${UNIT_SRC}" "${UNIT_DST}"
          systemctl daemon-reload
          systemctl enable --now scheduler.service
          systemctl restart scheduler.service

          sleep 3
          if ! systemctl is-active --quiet scheduler.service; then
            echo "scheduler.service is NOT active after restart" >&2
            journalctl -u scheduler.service -n 100 --no-pager || true
            exit 1
          fi
          EOS
          )

          B64=$(printf %s "$CMD" | base64 -w0)

          cat > /tmp/params.json <<JSON
          {
            "commands": [
              "set -euo pipefail",
              "echo ${B64} | base64 -d > /tmp/deploy.sh",
              "chmod +x /tmp/deploy.sh",
              "ARTIFACT_BUCKET=${ARTIFACT_BUCKET} OBJECT_KEY=${OBJECT_KEY} AWS_REGION=${AWS_REGION} bash /tmp/deploy.sh"
            ],
            "executionTimeout": ["600"],
            "workingDirectory": ["/"]
          }
          JSON

          COMMAND_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy backend" \
            --targets "Key=${BACKEND_SSM_TARGET_KEY},Values=${BACKEND_SSM_TARGET_VALUE}" \
            --parameters file:///tmp/params.json \
            --max-concurrency "1" \
            --max-errors "0" \
            --region "${AWS_REGION}" \
            --query "Command.CommandId" \
            --output text)

          echo "SSM CommandId: ${COMMAND_ID}"

          if [[ -z "${INSTANCE_IDS}" || "${INSTANCE_IDS}" == "None" ]]; then
            echo "WARN: No instance ids to wait on."
            exit 0
          fi

          FAIL=0
          for IID in ${INSTANCE_IDS}; do
            echo "Waiting for command on ${IID}..."
            aws ssm wait command-executed \
              --command-id "${COMMAND_ID}" \
              --instance-id "${IID}" \
              --region "${AWS_REGION}" || true

            STATUS=$(aws ssm get-command-invocation \
              --command-id "${COMMAND_ID}" \
              --instance-id "${IID}" \
              --region "${AWS_REGION}" \
              --query 'Status' --output text)

            echo "Instance ${IID} status: ${STATUS}"

            if ([[ "${STATUS}" != "Success" ]]); then
              echo "ERROR: Deployment failed on ${IID} (Status=${STATUS})" >&2
              echo "--- STDOUT ---"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${IID}" \
                --region "${AWS_REGION}" \
                --query 'StandardOutputContent' --output text || true
              echo "--- STDERR ---"
              aws ssm get-command-invocation \
                --command-id "${COMMAND_ID}" \
                --instance-id "${IID}" \
                --region "${AWS_REGION}" \
                --query 'StandardErrorContent' --output text || true
              FAIL=1
            fi
          done

          if [[ "${FAIL}" -ne 0 ]]; then
            exit 1
          fi

      - name: show last 80 journal lines (all matching instances)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --comment "Show scheduler.service logs" \
            --targets "Key=${BACKEND_SSM_TARGET_KEY},Values=${BACKEND_SSM_TARGET_VALUE}" \
            --parameters commands="journalctl -u scheduler.service -n 80 --no-pager || true" \
            --max-concurrency "1" \
            --max-errors "0" \
            --region "${AWS_REGION}" \
            --output text --query "Command.CommandId"
