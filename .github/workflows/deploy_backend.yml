name: Deploy Backend to EKS

on:
  workflow_dispatch: {}
  push:
    paths:
      - ".github/workflows/deploy_backend.yml"
      - "backend/**"
      - "infrastructure/docker/backend/Dockerfile"
      - "infrastructure/k8s/backend/**"
      - "infrastructure/k8s/externalsecrets/**"
      - "infrastructure/k8s/mongo/**"
      - "infrastructure/k8s/ingress/backend-ingress.yaml"
      - "infrastructure/k8s/secret-stores/clustersecretstore.yaml"

permissions:
  id-token: write
  contents: read

concurrency:
  group: deploy-backend
  cancel-in-progress: true

env:
  AWS_REGION: eu-central-1
  CLUSTER_NAME: nat20-eks
  PROJECT_NAME: nat20
  NAMESPACE: nat20
  ECR_REPO: nat20/backend
  API_HOST: api.nat20scheduling.com
  KUBECTL_TIMEOUT: 30s
  AWS_RETRY_MODE: standard
  AWS_MAX_ATTEMPTS: 6

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install tooling
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq curl ca-certificates gettext-base
          sudo update-ca-certificates

      - name: ECR login
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Compute image URI
        id: img
        shell: bash
        run: |
          set -euo pipefail
          echo "ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}" >> "$GITHUB_ENV"
          echo "IMAGE_URI=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPO }}:sha-${{ github.sha }}" >> "$GITHUB_ENV"
          echo "uri=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPO }}:sha-${{ github.sha }}" >> "$GITHUB_OUTPUT"

      - name: Build and push backend image
        shell: bash
        env:
          DOCKER_BUILDKIT: "1"
        run: |
          set -euo pipefail
          docker build -f infrastructure/docker/backend/Dockerfile -t "${IMAGE_URI}" .
          docker push "${IMAGE_URI}"

      - name: Read SSM params for backend ingress
        shell: bash
        run: |
          set -euo pipefail
          API_CERT_ARN="$(aws ssm get-parameter --name /${PROJECT_NAME}/network/API_CERT_ARN --query 'Parameter.Value' --output text)"
          ALB_BACKEND_SG_ID="$(aws ssm get-parameter --name /${PROJECT_NAME}/network/ALB_BACKEND_SG_ID --query 'Parameter.Value' --output text)"
          echo "API_CERT_ARN=${API_CERT_ARN}" >> "$GITHUB_ENV"
          echo "ALB_BACKEND_SG_ID=${ALB_BACKEND_SG_ID}" >> "$GITHUB_ENV"

      - name: kubeconfig
        shell: bash
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"
          kubectl version --client || true

      - name: "Preflight API reachability (200/401/403 OK)"
        id: preflight
        shell: bash
        run: |
          set -euo pipefail
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.endpoint' --output text)"
          ok="false"
          for i in 1 2 3; do
            code="$(curl -k -sS -o /dev/null -w '%{http_code}' --connect-timeout 5 --max-time 10 "${ENDPOINT}/version" || echo 000)"
            if [[ "$code" == "200" || "$code" == "401" || "$code" == "403" ]]; then
              ok="true"; break
            fi
            sleep 5
          done
          echo "ok=${ok}" >> "$GITHUB_OUTPUT"

      - name: "Fallback allow runner CIDR"
        if: steps.preflight.outputs.ok != 'true'
        shell: bash
        run: |
          set -euo pipefail
          RUNNER_CIDR="$(curl -s https://checkip.amazonaws.com | tr -d '\r\n')/32"
          echo "RUNNER_CIDR=${RUNNER_CIDR}" >> "$GITHUB_ENV"

          CUR_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json)"
          if [[ -z "${CUR_JSON}" || "${CUR_JSON}" == "null" ]]; then CUR_JSON='[]'; fi
          NEW_CSV="$(printf '%s' "${CUR_JSON}" | jq -r --arg ip "$RUNNER_CIDR" '(. // []) + [$ip] | unique | join(",")')"

          echo "Applying EKS update: endpointPublicAccess=true, publicAccessCidrs=${NEW_CSV}"
          UPDATE_ID="$(aws eks update-cluster-config \
            --name "${CLUSTER_NAME}" \
            --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${NEW_CSV}" \
            --query 'update.id' --output text)"

          for _ in {1..30}; do
            PHASE="$(aws eks describe-update --name "${CLUSTER_NAME}" --update-id "${UPDATE_ID}" --query 'update.status' --output text)"
            [[ "${PHASE}" == "Successful" ]] && break
            [[ "${PHASE}" == "Failed" ]] && { echo "EKS update failed"; exit 1; }
            sleep 10
          done

          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.endpoint' --output text)"
          code="$(curl -k -sS -o /dev/null -w '%{http_code}' --connect-timeout 5 --max-time 10 "${ENDPOINT}/version" || echo 000)"
          if [[ "$code" == "200" || "$code" == "401" || "$code" == "403" ]]; then
            echo "API now reachable (HTTP ${code})."
          else
            echo "API still not reachable (HTTP ${code}). Aborting."
            exit 1
          fi

      - name: Ensure namespaces and PSS labels
        shell: bash
        run: |
          set -euo pipefail
          kubectl get ns "${NAMESPACE}" >/dev/null 2>&1 || kubectl create ns "${NAMESPACE}"
          kubectl get ns externalsecrets >/dev/null 2>&1 || kubectl create ns externalsecrets
          kubectl label ns "${NAMESPACE}" \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite || true

      - name: Ensure External Secrets CRDs (pinned)
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply --server-side -f https://raw.githubusercontent.com/external-secrets/external-secrets/v0.19.2/deploy/crds/bundle.yaml
          kubectl wait --for=condition=Established crd clustersecretstores.external-secrets.io --timeout=90s
          kubectl wait --for=condition=Established crd secretstores.external-secrets.io --timeout=90s
          kubectl wait --for=condition=Established crd externalsecrets.external-secrets.io --timeout=90s

      - name: Apply ClusterSecretStore and backend ExternalSecret
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/secret-stores/clustersecretstore.yaml
          kubectl apply -n "${NAMESPACE}" -f infrastructure/k8s/externalsecrets/backend-secrets.yaml
          for i in {1..24}; do
            kubectl -n "${NAMESPACE}" get secret backend-env >/dev/null 2>&1 && break
            sleep 5
          done
          kubectl -n "${NAMESPACE}" get secret backend-env >/dev/null 2>&1 || { echo "backend-env Secret not materialized"; exit 1; }

      - name: Resolve cluster subnets for ALB annotation
        shell: bash
        run: |
          set -euo pipefail
          SUBNETS_CSV="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.resourcesVpcConfig.subnetIds' --output text | sed 's/\t/,/g')"
          [ -n "${SUBNETS_CSV:-}" ] || { echo "Could not resolve cluster subnets"; exit 1; }
          echo "ALB_PUBLIC_SUBNET_IDS=${SUBNETS_CSV}" >> "$GITHUB_ENV"

      - name: Apply backend Service and Deployment
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" apply -f infrastructure/k8s/backend/deployment.yaml --request-timeout="${KUBECTL_TIMEOUT}"

      - name: Apply backend Ingress (envsubst)
        shell: bash
        run: |
          set -euo pipefail
          export API_CERT_ARN ALB_BACKEND_SG_ID API_HOST ALB_PUBLIC_SUBNET_IDS
          TMP="$(mktemp)"
          envsubst < infrastructure/k8s/ingress/backend-ingress.yaml > "${TMP}"
          kubectl -n "${NAMESPACE}" apply -f "${TMP}" --request-timeout="${KUBECTL_TIMEOUT}"

      - name: Set image and rollout
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${NAMESPACE}" set image deployment/backend backend="${IMAGE_URI}" --record
          kubectl -n "${NAMESPACE}" annotate deployment/backend kubernetes.io/change-cause="kubectl set image to ${IMAGE_URI}" --overwrite
          kubectl -n "${NAMESPACE}" rollout status deployment/backend --timeout=300s

      - name: Wait for backend Ingress hostname
        id: alb
        shell: bash
        run: |
          set -euo pipefail
          for i in {1..24}; do
            HOST="$(kubectl -n "${NAMESPACE}" get ingress backend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)"
            [ -n "${HOST:-}" ] && [ "${HOST}" != "<no value>" ] && break
            sleep 5
          done
          [ -n "${HOST:-}" ] && [ "${HOST}" != "<no value>" ] || { kubectl -n "${NAMESPACE}" describe ingress backend || true; exit 1; }
          echo "BACKEND_ALB_DNS=${HOST}" >> "$GITHUB_ENV"
          echo "backend_alb_dns=${HOST}" >> "$GITHUB_OUTPUT"

      - name: "Cleanup temporary runner CIDR"
        if: always() && steps.preflight.outputs.ok != 'true'
        shell: bash
        run: |
          set -euo pipefail
          if [[ -z "${RUNNER_CIDR:-}" ]]; then
            echo "No RUNNER_CIDR set; skipping cleanup."; exit 0
          fi
          CUR_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json)"
          if [[ -z "${CUR_JSON}" || "${CUR_JSON}" == "null" ]]; then CUR_JSON='[]'; fi
          REST_CSV="$(printf '%s' "${CUR_JSON}" | jq -r --arg ip "$RUNNER_CIDR" '(. // []) | map(select(. != $ip)) | unique | join(",")')"

          echo "Reverting EKS publicAccessCidrs to: ${REST_CSV}"
          UPDATE_ID="$(aws eks update-cluster-config \
            --name "${CLUSTER_NAME}" \
            --resources-vpc-config "endpointPublicAccess=true,publicAccessCidrs=${REST_CSV}" \
            --query 'update.id' --output text)"

          for _ in {1..30}; do
            PHASE="$(aws eks describe-update --name "${CLUSTER_NAME}" --update-id "${UPDATE_ID}" --query 'update.status' --output text)"
            [[ "${PHASE}" == "Successful" ]] && break
            [[ "${PHASE}" == "Failed" ]] && { echo "Cleanup EKS update failed"; exit 1; }
            sleep 10
          done

      - name: "On failure: collect diagnostics"
        if: failure()
        shell: bash
        run: |
          set -euo pipefail
          echo "=== cluster nodes ==="
          kubectl get nodes -o wide || true

          echo "=== objects (backend ns) ==="
          kubectl -n "${NAMESPACE}" get all -o wide || true
          kubectl -n "${NAMESPACE}" describe deployment backend || true
          kubectl -n "${NAMESPACE}" get rs -o wide || true
          kubectl -n "${NAMESPACE}" get ingress backend -o yaml || true

          echo "=== recent events (unique lines with counts, last 300) ==="
          kubectl -n "${NAMESPACE}" get events --sort-by=.lastTimestamp | tail -n 300 \
            | awk '{c[$0]++} END {for (l in c) printf "%5d × %s\n", c[l], l}' | sort -nr | head -n 200 || true

          echo "=== backend pod logs (last 400, non-probe grouped) ==="
          for p in $(kubectl -n "${NAMESPACE}" get pods -l app=backend -o name | sed 's|pod/||'); do
            echo "--- $p ---"
            kubectl -n "${NAMESPACE}" logs "$p" --tail=400 2>/dev/null \
              | grep -v 'kube-probe/1' \
              | awk '{c[$0]++} END {for (l in c) printf "%5d × %s\n", c[l], l}' | sort -nr | head -n 200 || true
          done
