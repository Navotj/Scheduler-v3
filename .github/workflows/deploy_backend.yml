name: Deploy Backend to EKS

on:
  push:
    branches: ["main"]
    paths:
      - "backend/**"
      - ".github/workflows/deploy_backend.yml"
      - "infrastructure/docker/backend/Dockerfile"
      - "infrastructure/k8s/backend/**"
      - "infrastructure/k8s/externalsecrets/**"
      - "infrastructure/k8s/mongo/**"
      - "infrastructure/k8s/ingress/backend-ingress.yaml"
      - "infrastructure/k8s/secret-stores/clustersecretstore.yaml"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    env:
      AWS_REGION: eu-central-1
      CLUSTER_NAME: nat20-eks
      # Leave empty to auto-detect runner /32. Set to a CIDR list to override.
      EKS_JOB_PUBLIC_CIDRS: ""

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        timeout-minutes: 2

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        timeout-minutes: 2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: WhoAmI
        shell: bash
        timeout-minutes: 2
        run: |
          set -euo pipefail
          aws sts get-caller-identity
          aws configure list

      - name: Capture current EKS API CIDRs and endpoint (safe outputs)
        shell: bash
        timeout-minutes: 2
        run: |
          set -euo pipefail
          ENDPOINT="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.endpoint' --output text)"
          echo "EKS_ENDPOINT=${ENDPOINT}" >> "$GITHUB_ENV"

          CUR_JSON="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
            --query 'cluster.resourcesVpcConfig.publicAccessCidrs' --output json || echo '[]')"
          ORIG_B64="$(printf '%s' "${CUR_JSON}" | base64 -w0)"
          echo "EKS_ORIG_CIDRS_B64=${ORIG_B64}" >> "$GITHUB_ENV"

      - name: Open EKS API temporarily (runner /32 preferred) and quick probe
        shell: bash
        timeout-minutes: 4
        run: |
          set -euo pipefail
          if [ -z "${EKS_JOB_PUBLIC_CIDRS:-}" ]; then
            RIP="$(curl -s https://checkip.amazonaws.com/ | tr -d '\r')"
            if printf '%s' "$RIP" | grep -Eq '^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$'; then
              TARGET="${RIP}/32"
            else
              TARGET="0.0.0.0/0"
            fi
          else
            TARGET="${EKS_JOB_PUBLIC_CIDRS}"
          fi

          CUR_JSON="$(printf '%s' "${EKS_ORIG_CIDRS_B64:-}" | base64 -d 2>/dev/null || echo '[]')"
          CUR_JOIN="$(printf '%s' "${CUR_JSON}" | jq -r 'join(",")')"

          if [ -z "${CUR_JOIN}" ] || [ "${CUR_JOIN}" != "${TARGET}" ]; then
            set +e
            aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --resources-vpc-config publicAccessCidrs="${TARGET}" >/dev/null 2>err.txt
            rc=$?
            set -e
            if [ $rc -ne 0 ] && ! grep -qi "already at the desired configuration" err.txt; then
              echo "Failed to set temporary EKS API CIDRs:"; cat err.txt; exit 1
            fi
          fi

          HOST="$(echo "${EKS_ENDPOINT}" | sed -E 's#https?://##')"
          for i in 1 2 3; do
            if timeout 3 bash -lc "exec 3<>/dev/tcp/${HOST}/443" 2>/dev/null; then
              exec 3>&-
              echo "EKS endpoint reachable."
              exit 0
            fi
            sleep 2
          done
          echo "EKS endpoint NOT reachable after 3 tries."
          exit 1

      - name: Configure kubectl and wait until API responds
        shell: bash
        timeout-minutes: 4
        run: |
          set -euo pipefail
          aws eks update-kubeconfig --name "${CLUSTER_NAME}" --region "${AWS_REGION}"
          echo "Current context: $(kubectl config current-context || true)"
          OK=0
          for i in {1..12}; do
            if kubectl version --short >/dev/null 2>&1 && kubectl get --raw='/readyz?verbose' >/dev/null 2>&1; then
              OK=1; break
            fi
            sleep 5
          done
          [ $OK -eq 1 ] || { echo "kubectl not ready"; kubectl cluster-info dump | head -n 200 || true; exit 1; }

      - name: Resolve ECR URI and SSM parameters
        id: resolve
        shell: bash
        timeout-minutes: 3
        env:
          API_HOST: api.nat20scheduling.com
        run: |
          set -euo pipefail
          export AWS_PAGER=""; export AWS_CLI_PAGER=""; aws configure set cli_pager "" || true

          ECR_BACKEND_URI="$(aws ssm get-parameter --name /nat20/ecr/BACKEND_URI --query Parameter.Value --output text 2>/dev/null || true)"
          if [ -z "${ECR_BACKEND_URI:-}" ] || [ "${ECR_BACKEND_URI}" = "None" ]; then
            ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
            REPO_NAME="backend"
            ECR_BACKEND_URI="${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${REPO_NAME}"
            aws ecr describe-repositories --repository-names "${REPO_NAME}" >/dev/null 2>&1 || \
              aws ecr create-repository --repository-name "${REPO_NAME}" >/dev/null
          fi
          echo "ECR_BACKEND_URI=${ECR_BACKEND_URI}" >> "$GITHUB_ENV"

          API_CERT_ARN="$(aws ssm get-parameter --name /nat20/network/API_CERT_ARN --query Parameter.Value --output text 2>/dev/null || true)"
          ALB_BACKEND_SG_ID="$(aws ssm get-parameter --name /nat20/network/ALB_BACKEND_SG_ID --query Parameter.Value --output text 2>/dev/null || true)"
          [ -n "${API_CERT_ARN:-}" ] && [ "${API_CERT_ARN}" != "None" ] || { echo "Missing /nat20/network/API_CERT_ARN"; exit 1; }
          [ -n "${ALB_BACKEND_SG_ID:-}" ] && [ "${ALB_BACKEND_SG_ID}" != "None" ] || { echo "Missing /nat20/network/ALB_BACKEND_SG_ID"; exit 1; }
          echo "API_CERT_ARN=${API_CERT_ARN}" >> "$GITHUB_ENV"
          echo "ALB_BACKEND_SG_ID=${ALB_BACKEND_SG_ID}" >> "$GITHUB_ENV"
          echo "API_HOST=${API_HOST}" >> "$GITHUB_ENV"

      - name: Login to ECR
        uses: aws-actions/amazon-ecr-login@v2
        timeout-minutes: 2

      - name: Build and push backend image
        shell: bash
        timeout-minutes: 12
        run: |
          set -euo pipefail
          docker build -t "${ECR_BACKEND_URI}:${GITHUB_SHA}" -f infrastructure/docker/backend/Dockerfile .
          docker push "${ECR_BACKEND_URI}:${GITHUB_SHA}"
          echo "BACKEND_IMAGE=${ECR_BACKEND_URI}:${GITHUB_SHA}" >> "$GITHUB_ENV"

      - name: Update image in k8s manifest
        shell: bash
        timeout-minutes: 1
        run: |
          set -euo pipefail
          sed -i "s#<ECR_URI_REPLACED_BY_CI>/backend:\${GITHUB_SHA}#${ECR_BACKEND_URI}:${GITHUB_SHA}#g" infrastructure/k8s/backend/deployment.yaml

      - name: Ensure namespaces + PSS labels
        shell: bash
        timeout-minutes: 2
        run: |
          set -euo pipefail
          kubectl get ns nat20 >/dev/null 2>&1 || kubectl create ns nat20
          kubectl get ns externalsecrets >/dev/null 2>&1 || kubectl create ns externalsecrets
          kubectl label ns nat20 \
            pod-security.kubernetes.io/enforce=restricted \
            pod-security.kubernetes.io/audit=restricted \
            pod-security.kubernetes.io/warn=restricted \
            --overwrite || true

      - name: Ensure External Secrets CRDs (pinned)
        shell: bash
        timeout-minutes: 3
        run: |
          set -euo pipefail
          kubectl apply --server-side -f https://raw.githubusercontent.com/external-secrets/external-secrets/v0.19.2/deploy/crds/bundle.yaml
          kubectl wait --for=condition=Established crd clustersecretstores.external-secrets.io --timeout=90s
          kubectl wait --for=condition=Established crd secretstores.external-secrets.io --timeout=90s
          kubectl wait --for=condition=Established crd externalsecrets.external-secrets.io --timeout=90s

      - name: Resolve ALB subnets for this cluster
        shell: bash
        timeout-minutes: 1
        run: |
          set -euo pipefail
          SUBNETS_CSV="$(aws eks describe-cluster --name "${CLUSTER_NAME}" --region "${AWS_REGION}" --query 'cluster.resourcesVpcConfig.subnetIds' --output text | sed 's/\t/,/g')"
          [ -n "${SUBNETS_CSV:-}" ] || { echo "Could not resolve cluster subnets"; exit 1; }
          echo "ALB_PUBLIC_SUBNET_IDS=${SUBNETS_CSV}" >> "$GITHUB_ENV"

      - name: Preflight SSM for ExternalSecret
        shell: bash
        timeout-minutes: 1
        run: |
          set -euo pipefail
          M=0; for K in /nat20/backend/JWT_SECRET /nat20/mongo/USER /nat20/mongo/PASSWORD /nat20/mongo/DB; do
            aws ssm get-parameter --name "$K" >/dev/null 2>&1 || { echo "Missing $K"; M=1; }
          done
          [ $M -eq 0 ] || { echo "Required SSM parameters missing"; exit 1; }

      - name: Apply ClusterSecretStore and ExternalSecret
        shell: bash
        timeout-minutes: 4
        run: |
          set -euo pipefail
          kubectl apply -f infrastructure/k8s/secret-stores/clustersecretstore.yaml
          kubectl apply -n nat20 -f infrastructure/k8s/externalsecrets/backend-secrets.yaml
          for i in {1..24}; do
            kubectl -n nat20 get secret backend-env >/dev/null 2>&1 && break
            sleep 5
          done
          kubectl -n nat20 get secret backend-env >/dev/null 2>&1 || { echo "backend-env Secret not materialized"; exit 1; }

      - name: Render backend ingress (envsubst)
        shell: bash
        timeout-minutes: 1
        run: |
          set -euo pipefail
          : "${ALB_PUBLIC_SUBNET_IDS:?}"
          : "${API_CERT_ARN:?}"
          : "${ALB_BACKEND_SG_ID:?}"
          : "${API_HOST:?}"
          API_CERT_ARN="${API_CERT_ARN}" \
          ALB_BACKEND_SG_ID="${ALB_BACKEND_SG_ID}" \
          API_HOST="${API_HOST}" \
          ALB_PUBLIC_SUBNET_IDS="${ALB_PUBLIC_SUBNET_IDS}" \
          envsubst < infrastructure/k8s/ingress/backend-ingress.yaml > /tmp/backend-ingress.rendered.yaml

      - name: Apply backend Service/Deployment and Ingress
        shell: bash
        timeout-minutes: 8
        run: |
          set -euo pipefail
          kubectl apply -n nat20 -f infrastructure/k8s/backend/deployment.yaml
          kubectl apply -f /tmp/backend-ingress.rendered.yaml
          kubectl -n nat20 rollout status deployment/backend --timeout=5m

      - name: Wait for Backend Ingress hostname (ALB)
        id: alb
        shell: bash
        timeout-minutes: 3
        run: |
          set -euo pipefail
          for i in {1..18}; do
            HOST="$(kubectl -n nat20 get ingress backend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)"
            [ -n "${HOST:-}" ] && [ "${HOST}" != "<no value>" ] && break
            sleep 5
          done
          [ -n "${HOST:-}" ] && [ "${HOST}" != "<no value>" ] || { kubectl -n nat20 describe ingress backend || true; exit 1; }
          echo "BACKEND_ALB_DNS=${HOST}" >> "$GITHUB_ENV"
          echo "backend_alb_dns=${HOST}" >> "$GITHUB_OUTPUT"

      - name: Restore original EKS API CIDRs
        if: always()
        shell: bash
        timeout-minutes: 3
        run: |
          set -euo pipefail
          ORIG_JSON="$(printf '%s' "${EKS_ORIG_CIDRS_B64:-}" | base64 -d 2>/dev/null || echo '[]')"
          WANT="$(printf '%s' "${ORIG_JSON}" | jq -r 'join(",")')"
          if [ -n "${WANT}" ]; then
            aws eks update-cluster-config --name "${CLUSTER_NAME}" --region "${AWS_REGION}" \
              --resources-vpc-config publicAccessCidrs="${WANT}" >/dev/null || true
          fi
