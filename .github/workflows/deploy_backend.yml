name: deploy-backend

on:
  workflow_dispatch: {}
  push:
    branches: [ "main" ]
    paths:
      - 'backend/**'
      - '.github/workflows/deploy_backend.yml'
      - 'infrastucture/terraform/scripts/user_data_backend.sh'

concurrency:
  group: deploy-backend-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

env:
  APP_PREFIX: ${{ vars.APP_PREFIX }}
  AWS_REGION: ${{ vars.AWS_REGION }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    steps:
      - name: checkout
        uses: actions/checkout@v5

      - name: configure aws credentials (keys only)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: ensure aws cli
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v aws >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y unzip >/dev/null
            curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o awscliv2.zip
            unzip -q awscliv2.zip
            sudo ./aws/install
          fi
          aws --version

      - name: sanity checks
        shell: bash
        run: |
          set -euo pipefail
          [[ -n "${APP_PREFIX}" ]] || { echo "APP_PREFIX is empty"; exit 1; }
          [[ -n "${AWS_REGION}"  ]] || { echo "AWS_REGION is empty";  exit 1; }
          [[ -d "backend/app" ]] || { echo "missing: backend/app"; ls -la backend || true; exit 1; }
          [[ -f "backend/scheduler.service" ]] || { echo "missing: backend/scheduler.service"; exit 1; }
          aws sts get-caller-identity >/dev/null

      - name: resolve artifact bucket (create if missing)
        id: bucket
        shell: bash
        run: |
          set -euo pipefail
          BUCKET="${BACKEND_ARTIFACT_BUCKET:-${APP_PREFIX}-backend-artifacts}"
          echo "bucket=${BUCKET}" >> "$GITHUB_OUTPUT"

          if aws s3api head-bucket --bucket "${BUCKET}" 2>/dev/null; then
            echo "Using existing bucket: ${BUCKET}"
          else
            echo "Creating bucket: ${BUCKET} in ${AWS_REGION}"
            if [[ "${AWS_REGION}" == "us-east-1" ]]; then
              aws s3api create-bucket --bucket "${BUCKET}" >/dev/null
            else
              aws s3api create-bucket --bucket "${BUCKET}" --create-bucket-configuration LocationConstraint="${AWS_REGION}" >/dev/null
            fi
            # basic hardening: block public access
            aws s3api put-public-access-block \
              --bucket "${BUCKET}" \
              --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true >/dev/null
          fi

      - name: package backend app (zip contents only)
        id: pkg
        shell: bash
        run: |
          set -euo pipefail
          BUILD_ID="$(date -u +%Y%m%dT%H%M%SZ)-${GITHUB_SHA::7}"
          echo "build_id=${BUILD_ID}" >> "$GITHUB_OUTPUT"

          # Zip the CONTENTS of backend/app (no extra top-level folder in the archive)
          rm -f app.zip
          ( cd backend/app && zip -qr "../../app.zip" . )
          stat -c 'archive bytes: %s' app.zip

          # Upload artifacts to S3 (zip + systemd unit)
          BUCKET="${{ steps.bucket.outputs.bucket }}"
          ZIP_KEY="releases/${BUILD_ID}/app.zip"
          SVC_KEY="releases/${BUILD_ID}/scheduler.service"

          aws s3 cp app.zip "s3://${BUCKET}/${ZIP_KEY}" --sse AES256 --only-show-errors
          aws s3 cp backend/scheduler.service "s3://${BUCKET}/${SVC_KEY}" --sse AES256 --only-show-errors

          echo "zip_key=${ZIP_KEY}" >> "$GITHUB_OUTPUT"
          echo "svc_key=${SVC_KEY}" >> "$GITHUB_OUTPUT"

      - name: find backend instance (by tags)
        id: ec2
        shell: bash
        run: |
          set -euo pipefail
          # Defaults if not provided via env/vars
          TAG_APP_KEY="app"
          TAG_ROLE_KEY="${BACKEND_TAG_KEY:-role}"
          TAG_ROLE_VAL="${BACKEND_TAG_VALUE:-backend}"

          echo "Searching for running EC2 with tags: ${TAG_APP_KEY}=${APP_PREFIX}, ${TAG_ROLE_KEY}=${TAG_ROLE_VAL}"
          IID="$(aws ec2 describe-instances \
            --filters "Name=instance-state-name,Values=running" \
                      "Name=tag:${TAG_APP_KEY},Values=${APP_PREFIX}" \
                      "Name=tag:${TAG_ROLE_KEY},Values=${TAG_ROLE_VAL}" \
            --query 'Reservations[].Instances[].InstanceId' --output text | awk '{print $1}')"

          if [[ -z "${IID}" || "${IID}" == "None" ]]; then
            # Fallback: Name = "${APP_PREFIX}-backend"
            echo "Tag query empty; fallback to Name=${APP_PREFIX}-backend"
            IID="$(aws ec2 describe-instances \
              --filters "Name=instance-state-name,Values=running" \
                        "Name=tag:Name,Values=${APP_PREFIX}-backend" \
              --query 'Reservations[].Instances[].InstanceId' --output text | awk '{print $1}')"
          fi

          [[ -n "${IID}" && "${IID}" != "None" ]] || { echo "No running backend instance found"; exit 1; }
          echo "instance_id=${IID}" >> "$GITHUB_OUTPUT"

      - name: push and activate via ssm
        id: ssm
        shell: bash
        run: |
          set -euo pipefail
          IID="${{ steps.ec2.outputs.instance_id }}"
          BUCKET="${{ steps.bucket.outputs.bucket }}"
          ZIP_KEY="${{ steps.pkg.outputs.zip_key }}"
          SVC_KEY="${{ steps.pkg.outputs.svc_key }}"

          # ensure jq for safe JSON escaping
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y
            sudo apt-get install -y jq >/dev/null
          fi

          echo "Sending SSM command to ${IID}"

          # Build the remote script (no Unicode, ASCII only)
          REMOTE_SCRIPT="$(cat <<EOS
          set -euo pipefail

          which unzip >/dev/null 2>&1 || sudo dnf install -y unzip || sudo yum install -y unzip || true
          which aws   >/dev/null 2>&1 || { echo "aws cli not found on instance"; exit 1; }

          BUCKET="${BUCKET}"
          ZIP_KEY="${ZIP_KEY}"
          SVC_KEY="${SVC_KEY}"

          sudo mkdir -p /opt/app
          sudo chown ec2-user:ec2-user /opt/app
          sudo chmod 755 /opt/app

          if systemctl list-unit-files | grep -q '^scheduler.service'; then
            sudo systemctl stop scheduler.service || true
          fi

          tmpdir="\$(mktemp -d)"
          aws s3 cp "s3://${BUCKET}/${ZIP_KEY}" "\${tmpdir}/app.zip" --only-show-errors
          aws s3 cp "s3://${BUCKET}/${SVC_KEY}" "\${tmpdir}/scheduler.service" --only-show-errors

          sudo unzip -o "\${tmpdir}/app.zip" -d /opt/app >/dev/null
          sudo chown -R ec2-user:ec2-user /opt/app

          sudo install -m 0644 "\${tmpdir}/scheduler.service" /etc/systemd/system/scheduler.service
          sudo systemctl daemon-reload
          sudo systemctl enable scheduler.service
          sudo systemctl start scheduler.service

          for i in \$(seq 1 20); do
            if systemctl is-active --quiet scheduler.service; then
              systemctl --no-pager --full status scheduler.service || true
              exit 0
            fi
            sleep 1
          done
          echo "scheduler.service failed to become active"
          systemctl --no-pager --full status scheduler.service || true
          journalctl -u scheduler.service -n 200 --no-pager || true
          exit 1
          EOS
          )"

          # JSON-encode parameters for AWS-RunShellScript: {"commands":["<script>"]}
          PARAMS_JSON="$(jq -Rn --arg s "$REMOTE_SCRIPT" '{commands: [$s]}')"

          CMD_ID="$(
            aws ssm send-command \
              --instance-ids "${IID}" \
              --document-name "AWS-RunShellScript" \
              --comment "Deploy backend build ${{ steps.pkg.outputs.build_id }}" \
              --parameters "${PARAMS_JSON}" \
              --query "Command.CommandId" --output text
          )"

          [[ -n "${CMD_ID}" ]] || { echo "Failed to send SSM command"; exit 1; }

          echo "Waiting for SSM command to complete..."
          aws ssm wait command-executed --command-id "${CMD_ID}" --instance-id "${IID}"

          STATUS="$(aws ssm list-command-invocations --command-id "${CMD_ID}" --details \
                    --query 'CommandInvocations[0].Status' --output text)"
          echo "SSM command status: ${STATUS}"
          [[ "${STATUS}" == "Success" ]]


      - name: done
        if: success()
        shell: bash
        run: echo "Backend deployment completed successfully."
