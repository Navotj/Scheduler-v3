name: Deploy Backend to EC2

on:
  push:
    branches: [ "main" ]
    paths:
      - "backend/**"
      - ".github/workflows/deploy_backend.yml"
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-central-1

      - name: Derive artifact bucket name
        id: acct
        run: |
          set -euo pipefail
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
          ARTIFACT_BUCKET="nat20scheduling-com-deploy-artifacts-$ACCOUNT_ID"
          echo "ARTIFACT_BUCKET=$ARTIFACT_BUCKET" >> $GITHUB_ENV

      - name: Verify artifact bucket exists (managed by Terraform)
        run: |
          set -euo pipefail
          if ! aws s3api head-bucket --bucket "$ARTIFACT_BUCKET" 2>/dev/null; then
            echo "Artifact bucket $ARTIFACT_BUCKET does not exist. Run the Terraform workflow first." >&2
            exit 1
          fi

      - name: Get Backend Instance ID from tag
        id: backend_instance
        run: |
          set -euo pipefail
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=terraform-backend" "Name=instance-state-name,Values=running" \
            --query "Reservations[0].Instances[0].InstanceId" \
            --output text)
          if [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = "None" ]; then
            echo "No running instance tagged Name=terraform-backend" >&2
            exit 1
          fi
          echo "INSTANCE_ID=$INSTANCE_ID" >> $GITHUB_ENV
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

      - name: Build production bundle (vendor node_modules + Node binaries)
        uses: actions/setup-node@v4
        with:
          node-version: '22'
      - name: Create bundle
        run: |
          set -euo pipefail
          # Tools
          if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq; fi
          if ! command -v curl >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y curl; fi

          # Prepare staging dir
          rm -rf pack backend.zip
          mkdir -p pack
          rsync -a --delete backend/ pack/

          # Install prod deps into pack (no dev deps)
          pushd pack >/dev/null
          if [ -f package-lock.json ]; then
            npm ci --omit=dev
          else
            npm install --omit=dev
          fi
          popd >/dev/null

          # Determine latest Node v22.x and vendor linux binaries (x64 + arm64)
          set +e
          NODE_VERSION=$(curl -fsSL https://nodejs.org/dist/index.json | jq -r '[.[] | select(.version | test("^v22\\."))][0].version')
          set -e
          : "${NODE_VERSION:=v22.7.0}"

          mkdir -p pack/bin

          curl -fsSL "https://nodejs.org/dist/${NODE_VERSION}/node-${NODE_VERSION}-linux-x64.tar.xz" -o /tmp/node-x64.tar.xz
          tar -xJf /tmp/node-x64.tar.xz --strip-components=2 -C pack/bin "node-${NODE_VERSION}-linux-x64/bin/node"
          mv pack/bin/node pack/bin/node-linux-x64

          curl -fsSL "https://nodejs.org/dist/${NODE_VERSION}/node-${NODE_VERSION}-linux-arm64.tar.xz" -o /tmp/node-arm64.tar.xz
          tar -xJf /tmp/node-arm64.tar.xz --strip-components=2 -C pack/bin "node-${NODE_VERSION}-linux-arm64/bin/node"
          mv pack/bin/node pack/bin/node-linux-arm64

          # Portable launcher that selects the correct binary at runtime
          cat > pack/bin/node <<'EOS'
          #!/usr/bin/env bash
          set -euo pipefail
          ARCH="$(uname -m)"
          DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
          case "$ARCH" in
            x86_64) exec "$DIR/node-linux-x64" "$@" ;;
            aarch64|arm64) exec "$DIR/node-linux-arm64" "$@" ;;
            *) echo "Unsupported architecture: $ARCH" >&2; exit 1 ;;
          esac
          EOS
          chmod +x pack/bin/node pack/bin/node-linux-x64 pack/bin/node-linux-arm64

          # Force a known-good systemd unit that uses the vendored Node
          cat > pack/scheduler.service <<'UNIT'
          [Unit]
          Description=NAT20 Backend (Node.js)
          After=network-online.target
          Wants=network-online.target

          [Service]
          Type=simple
          WorkingDirectory=/opt/app
          EnvironmentFile=/opt/app/.env
          ExecStart=/opt/app/bin/node /opt/app/app.js
          Restart=always
          RestartSec=2
          NoNewPrivileges=true

          # Hardening (tune as needed)
          ProtectSystem=full
          ProtectHome=true
          PrivateTmp=true

          [Install]
          WantedBy=multi-user.target
          UNIT

          # Zip the pack dir as backend.zip at repo root
          (cd pack && zip -r ../backend.zip .)

      - name: Upload artifact to private S3 (encrypted)
        run: |
          set -euo pipefail
          KEY="backend/${GITHUB_SHA}.zip"
          echo "ARTIFACT_KEY=$KEY" >> $GITHUB_ENV
          aws s3 cp backend.zip "s3://$ARTIFACT_BUCKET/$KEY" --sse AES256

      - name: Deploy on instance via SSM (download from S3, write .env, install unit)
        env:
          INSTANCE_ID: ${{ env.INSTANCE_ID }}
          ARTIFACT_BUCKET: ${{ env.ARTIFACT_BUCKET }}
          ARTIFACT_KEY: ${{ env.ARTIFACT_KEY }}
        run: |
          set -euo pipefail

          cat > /tmp/ssm_commands.txt <<CMDS
          set -euo pipefail

          # Ensure basic tools exist
          if ! command -v unzip >/dev/null 2>&1; then
            if command -v dnf >/dev/null 2>&1; then dnf install -y unzip; elif command -v yum >/dev/null 2>&1; then yum install -y unzip; elif command -v apt-get >/dev/null 2>&1; then apt-get update -y && apt-get install -y unzip; fi
          fi
          if ! command -v rsync >/dev/null 2>&1; then
            if command -v dnf >/dev/null 2>&1; then dnf install -y rsync; elif command -v yum >/dev/null 2>&1; then yum install -y rsync; elif command -v apt-get >/dev/null 2>&1; then apt-get update -y && apt-get install -y rsync; fi
          fi

          sudo mkdir -p /opt/app /tmp/installation
          sudo chown -R root:root /tmp/installation

          # Download and extract artifact (runner expanded bucket/key)
          aws s3 cp "s3://${ARTIFACT_BUCKET}/${ARTIFACT_KEY}" /tmp/installation/backend.zip
          rm -rf /tmp/installation/unpack
          mkdir -p /tmp/installation/unpack
          unzip -o /tmp/installation/backend.zip -d /tmp/installation/unpack/

          # Sync into /opt/app
          SRC="/tmp/installation/unpack"
          sudo rsync -a --delete "$SRC"/ /opt/app/

          # Permissions for vendored node binaries
          sudo chmod +x /opt/app/bin/node || true
          sudo chmod +x /opt/app/bin/node-linux-* || true

          # Fetch secrets from SSM
          JWT_SECRET=\$(aws ssm get-parameter --name /nat20/backend/JWT_SECRET --with-decryption --query Parameter.Value --output text)
          MONGO_USER=\$(aws ssm get-parameter --name /nat20/mongo/USER --with-decryption --query Parameter.Value --output text)
          MONGO_PASS=\$(aws ssm get-parameter --name /nat20/mongo/PASSWORD --with-decryption --query Parameter.Value --output text)
          MONGO_HOST=\$(aws ssm get-parameter --name /nat20/mongo/HOST --with-decryption --query Parameter.Value --output text)
          MONGO_DB=\$(aws ssm get-parameter --name /nat20/mongo/DB --with-decryption --query Parameter.Value --output text)

          # Write .env
          {
            echo JWT_SECRET=\$JWT_SECRET
            echo MONGO_URI=mongodb://\$MONGO_USER:\$MONGO_PASS@\$MONGO_HOST:27017/\$MONGO_DB?authSource=admin
            echo MONGO_DB_NAME=\$MONGO_DB
            echo PORT=3000
            echo COOKIE_SECURE=true
          } | sudo tee /opt/app/.env >/dev/null

          # Install our known-good service unit (always overwrite)
          sudo cp -f /opt/app/scheduler.service /etc/systemd/system/scheduler.service

          sudo systemctl daemon-reload
          sudo systemctl enable scheduler || true
          sudo systemctl restart scheduler || (journalctl -u scheduler --no-pager -n 200; exit 1)

          sleep 2; ss -lntp | sed -n "1,200p" || true
          curl -sS -o /dev/null -w 'HTTP:%{http_code}\n' http://127.0.0.1:3000/ || true
          rm -rf /tmp/installation
          CMDS

          # Convert to JSON for SSM and execute
          jq -Rs '{commands: (split("\n") | map(select(length>0)))}' /tmp/ssm_commands.txt > /tmp/ssm_params.json

          CMD_ID=$(aws ssm send-command \
            --document-name "AWS-RunShellScript" \
            --instance-ids "$INSTANCE_ID" \
            --region eu-central-1 \
            --comment "Deploy backend (vendored node + node_modules; secrets from SSM)" \
            --parameters file:///tmp/ssm_params.json \
            --query "Command.CommandId" --output text)

          echo "Waiting for SSM command ${CMD_ID} to finish..."
          for i in $(seq 1 60); do
            STATUS=$(aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --query Status --output text || echo "Pending")
            if [ "$STATUS" = "Success" ]; then
              break
            fi
            if [ "$STATUS" = "Failed" ] || [ "$STATUS" = "Cancelled" ] || [ "$STATUS" = "TimedOut" ]; then
              echo "SSM status: $STATUS"
              echo "SSM STDOUT"
              aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --query 'StandardOutputContent' --output text || true
              echo
              echo "SSM STDERR"
              aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --query 'StandardErrorContent' --output text || true
              echo
              echo "Remote deploy script failed with status: $STATUS" >&2
              exit 1
            fi
            sleep 5
          done

          echo "SSM status: Success"
          echo "SSM STDOUT"
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --query 'StandardOutputContent' --output text || true
          echo
          echo "SSM STDERR"
          aws ssm get-command-invocation --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" --query 'StandardErrorContent' --output text || true
          echo

      - name: Clean up local artifact
        if: always()
        run: rm -f backend.zip
